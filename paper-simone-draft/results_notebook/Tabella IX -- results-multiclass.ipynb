{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fathead Minnow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from helper_knn import *\n",
    "\n",
    "db = pd.read_csv('lc_db_processed.csv').drop(columns = 'Unnamed: 0')\n",
    "\n",
    "db = pd.concat([db,\n",
    "                pd.DataFrame(pd.DataFrame(db['pubchem2d'].values).\\\n",
    "                             apply(lambda x: x.str.replace('', ' ').str.strip().str.split(' '), \n",
    "                                                                        axis = 1)[0].to_list(),\n",
    "                   columns = ['pub'+ str(i) for i in range(1,882)])],\n",
    "               axis = 1)\n",
    "\n",
    "species = pd.read_csv('C:/Users/Simone/Desktop/Utilit√† tesi magistrale/data/species.txt', sep = '\\|', engine = 'python')\n",
    "\n",
    "fm = species[species['common_name'] == 'Fathead Minnow'][\n",
    "    ['class', 'tax_order', 'family', 'genus', 'species']].values.ravel()\n",
    "\n",
    "X_train = db.loc[(db[\n",
    "    ['class', 'tax_order', 'family', 'genus', 'species']] == fm).all(axis =1)].copy().reset_index(drop=True)\n",
    "y_train = multiclass_encoding(X_train['conc1_mean'].copy())\n",
    "\n",
    "X_test = db.loc[~(db[\n",
    "    ['class', 'tax_order', 'family', 'genus', 'species']] == fm).all(axis = 1)].copy().reset_index(drop=True)\n",
    "y_test = multiclass_encoding(X_test['conc1_mean'].copy())\n",
    "\n",
    "categorical = ['test_cas', 'fish', 'smiles', 'pubchem2d', 'conc1_mean', 'obs_duration_mean',\n",
    "               'conc1_type', 'exposure_type', 'control_type', 'media_type',\n",
    "               'application_freq_unit', 'species', 'class', 'tax_order', 'family', 'genus']\n",
    "X_train.drop(columns = categorical, inplace = True)\n",
    "X_test.drop(columns = categorical, inplace = True)\n",
    "\n",
    "numerical = ['atom_number', 'bonds_number','Mol', 'MorganDensity', 'LogP',\n",
    "            'alone_atom_number', 'doubleBond', 'tripleBond', 'ring_number', 'oh_count', 'MeltingPoint', 'WaterSolubility']\n",
    "\n",
    "minmax = MinMaxScaler()\n",
    "minmax.fit(X_train[numerical])\n",
    "\n",
    "new_train = X_train.copy()\n",
    "new_train.loc[:, numerical] = minmax.transform(X_train[numerical])\n",
    "\n",
    "new_test = X_test.copy()\n",
    "new_test.loc[:, numerical] = minmax.transform(X_test[numerical])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 3 5 7 9 11 13 15 17 19 21 31 \n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "metrics = pd.DataFrame(index = ['Acc',\n",
    "                                'Sens (micro)', 'Sens (macro)', 'Sens (weighted)',\n",
    "                                'Prec (micro)', 'Prec (macro)', 'Prec (weighted)',\n",
    "                                'F1 (micro)', 'F1 (macro)', 'F1 (weighted)'])\n",
    "for k in [1,3,5,7,9,11,13,15,17,19,21,31]:\n",
    "    print(k, end = ' ')\n",
    "    knn = KNeighborsClassifier(n_neighbors = k, n_jobs = -1)\n",
    "    knn.fit(new_train, y_train)\n",
    "    y_pred = knn.predict(new_test)\n",
    "    \n",
    "    metrics = pd.concat([ metrics,\n",
    "                         pd.DataFrame([accuracy_score(y_test, y_pred),\n",
    "                                       \n",
    "                                       recall_score(y_test, y_pred, average = 'micro'),\n",
    "                                       recall_score(y_test, y_pred, average = 'macro'),\n",
    "                                       recall_score(y_test, y_pred, average = 'weighted'),\n",
    "                                       \n",
    "                                       precision_score(y_test, y_pred, average = 'micro'),\n",
    "                                       precision_score(y_test, y_pred, average = 'macro'),\n",
    "                                       precision_score(y_test, y_pred, average = 'weighted'),\n",
    "                                       \n",
    "                                       f1_score(y_test, y_pred, average = 'micro'),\n",
    "                                       f1_score(y_test, y_pred, average = 'macro'),\n",
    "                                       f1_score(y_test, y_pred, average = 'weighted')], \n",
    "                                                index = ['Acc',\n",
    "                                'Sens (micro)', 'Sens (macro)', 'Sens (weighted)',\n",
    "                                'Prec (micro)', 'Prec (macro)', 'Prec (weighted)',\n",
    "                                'F1 (micro)', 'F1 (macro)', 'F1 (weighted)'])], axis = 1)\n",
    "\n",
    "print('')\n",
    "metrics = metrics.T.reset_index(drop=True)\n",
    "metrics['K'] = pd.Series([1,3,5,7,9,11,13,15,17,19,21,31])\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(metrics['K'], metrics['Acc'], '-o')\n",
    "plt.xlabel('K', fontsize = 15)\n",
    "plt.ylabel('Accuracy', fontsize = 15)\n",
    "plt.title('KNN Table IX', fontsize = 15)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Acc</th>\n",
       "      <th>Sens (micro)</th>\n",
       "      <th>Sens (macro)</th>\n",
       "      <th>Sens (weighted)</th>\n",
       "      <th>Prec (micro)</th>\n",
       "      <th>Prec (macro)</th>\n",
       "      <th>Prec (weighted)</th>\n",
       "      <th>F1 (micro)</th>\n",
       "      <th>F1 (macro)</th>\n",
       "      <th>F1 (weighted)</th>\n",
       "      <th>K</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.509596</td>\n",
       "      <td>0.509596</td>\n",
       "      <td>0.510848</td>\n",
       "      <td>0.509596</td>\n",
       "      <td>0.509596</td>\n",
       "      <td>0.523552</td>\n",
       "      <td>0.528630</td>\n",
       "      <td>0.509596</td>\n",
       "      <td>0.513313</td>\n",
       "      <td>0.515019</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.500867</td>\n",
       "      <td>0.500867</td>\n",
       "      <td>0.503215</td>\n",
       "      <td>0.500867</td>\n",
       "      <td>0.500867</td>\n",
       "      <td>0.522179</td>\n",
       "      <td>0.529688</td>\n",
       "      <td>0.500867</td>\n",
       "      <td>0.503858</td>\n",
       "      <td>0.506531</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.502486</td>\n",
       "      <td>0.502486</td>\n",
       "      <td>0.504965</td>\n",
       "      <td>0.502486</td>\n",
       "      <td>0.502486</td>\n",
       "      <td>0.515435</td>\n",
       "      <td>0.522932</td>\n",
       "      <td>0.502486</td>\n",
       "      <td>0.503247</td>\n",
       "      <td>0.505974</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.496069</td>\n",
       "      <td>0.496069</td>\n",
       "      <td>0.500120</td>\n",
       "      <td>0.496069</td>\n",
       "      <td>0.496069</td>\n",
       "      <td>0.506028</td>\n",
       "      <td>0.514062</td>\n",
       "      <td>0.496069</td>\n",
       "      <td>0.498249</td>\n",
       "      <td>0.500680</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.481963</td>\n",
       "      <td>0.481963</td>\n",
       "      <td>0.488117</td>\n",
       "      <td>0.481963</td>\n",
       "      <td>0.481963</td>\n",
       "      <td>0.492005</td>\n",
       "      <td>0.500595</td>\n",
       "      <td>0.481963</td>\n",
       "      <td>0.484237</td>\n",
       "      <td>0.486342</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.480460</td>\n",
       "      <td>0.480460</td>\n",
       "      <td>0.487483</td>\n",
       "      <td>0.480460</td>\n",
       "      <td>0.480460</td>\n",
       "      <td>0.487105</td>\n",
       "      <td>0.498065</td>\n",
       "      <td>0.480460</td>\n",
       "      <td>0.481347</td>\n",
       "      <td>0.484415</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.457452</td>\n",
       "      <td>0.457452</td>\n",
       "      <td>0.463815</td>\n",
       "      <td>0.457452</td>\n",
       "      <td>0.457452</td>\n",
       "      <td>0.458010</td>\n",
       "      <td>0.467266</td>\n",
       "      <td>0.457452</td>\n",
       "      <td>0.453528</td>\n",
       "      <td>0.456364</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.459649</td>\n",
       "      <td>0.459649</td>\n",
       "      <td>0.464698</td>\n",
       "      <td>0.459649</td>\n",
       "      <td>0.459649</td>\n",
       "      <td>0.460532</td>\n",
       "      <td>0.468638</td>\n",
       "      <td>0.459649</td>\n",
       "      <td>0.457604</td>\n",
       "      <td>0.460060</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.450283</td>\n",
       "      <td>0.450283</td>\n",
       "      <td>0.455536</td>\n",
       "      <td>0.450283</td>\n",
       "      <td>0.450283</td>\n",
       "      <td>0.450413</td>\n",
       "      <td>0.460106</td>\n",
       "      <td>0.450283</td>\n",
       "      <td>0.446766</td>\n",
       "      <td>0.450309</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.430223</td>\n",
       "      <td>0.430223</td>\n",
       "      <td>0.436068</td>\n",
       "      <td>0.430223</td>\n",
       "      <td>0.430223</td>\n",
       "      <td>0.435370</td>\n",
       "      <td>0.446248</td>\n",
       "      <td>0.430223</td>\n",
       "      <td>0.427689</td>\n",
       "      <td>0.431921</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.422419</td>\n",
       "      <td>0.422419</td>\n",
       "      <td>0.429759</td>\n",
       "      <td>0.422419</td>\n",
       "      <td>0.422419</td>\n",
       "      <td>0.430569</td>\n",
       "      <td>0.441497</td>\n",
       "      <td>0.422419</td>\n",
       "      <td>0.420046</td>\n",
       "      <td>0.423746</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.417216</td>\n",
       "      <td>0.417216</td>\n",
       "      <td>0.429469</td>\n",
       "      <td>0.417216</td>\n",
       "      <td>0.417216</td>\n",
       "      <td>0.433395</td>\n",
       "      <td>0.443855</td>\n",
       "      <td>0.417216</td>\n",
       "      <td>0.419009</td>\n",
       "      <td>0.420196</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Acc  Sens (micro)  Sens (macro)  Sens (weighted)  Prec (micro)  \\\n",
       "0   0.509596      0.509596      0.510848         0.509596      0.509596   \n",
       "1   0.500867      0.500867      0.503215         0.500867      0.500867   \n",
       "2   0.502486      0.502486      0.504965         0.502486      0.502486   \n",
       "3   0.496069      0.496069      0.500120         0.496069      0.496069   \n",
       "4   0.481963      0.481963      0.488117         0.481963      0.481963   \n",
       "5   0.480460      0.480460      0.487483         0.480460      0.480460   \n",
       "6   0.457452      0.457452      0.463815         0.457452      0.457452   \n",
       "7   0.459649      0.459649      0.464698         0.459649      0.459649   \n",
       "8   0.450283      0.450283      0.455536         0.450283      0.450283   \n",
       "9   0.430223      0.430223      0.436068         0.430223      0.430223   \n",
       "10  0.422419      0.422419      0.429759         0.422419      0.422419   \n",
       "11  0.417216      0.417216      0.429469         0.417216      0.417216   \n",
       "\n",
       "    Prec (macro)  Prec (weighted)  F1 (micro)  F1 (macro)  F1 (weighted)   K  \n",
       "0       0.523552         0.528630    0.509596    0.513313       0.515019   1  \n",
       "1       0.522179         0.529688    0.500867    0.503858       0.506531   3  \n",
       "2       0.515435         0.522932    0.502486    0.503247       0.505974   5  \n",
       "3       0.506028         0.514062    0.496069    0.498249       0.500680   7  \n",
       "4       0.492005         0.500595    0.481963    0.484237       0.486342   9  \n",
       "5       0.487105         0.498065    0.480460    0.481347       0.484415  11  \n",
       "6       0.458010         0.467266    0.457452    0.453528       0.456364  13  \n",
       "7       0.460532         0.468638    0.459649    0.457604       0.460060  15  \n",
       "8       0.450413         0.460106    0.450283    0.446766       0.450309  17  \n",
       "9       0.435370         0.446248    0.430223    0.427689       0.431921  19  \n",
       "10      0.430569         0.441497    0.422419    0.420046       0.423746  21  \n",
       "11      0.433395         0.443855    0.417216    0.419009       0.420196  31  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu May  6 10:23:14 2021\n",
      "Thu May  6 10:33:56 2021\n",
      "Model: {'n_estimators': 920, 'min_samples_split': 2, 'min_samples_leaf': 2, 'max_depth': 18}\n",
      "Accuracy:             0.5407561567811308\n",
      "\n",
      "Micro Recall:         0.5407561567811308\n",
      "Macro Recall:         0.5437252411290127\n",
      "Weighted Recall:      0.5407561567811308\n",
      "\n",
      "Micro Precision:      0.5407561567811308\n",
      "Macro Precision:      0.5467809366610823\n",
      "Weighted Precision:   0.5468030020360778\n",
      "\n",
      "Micro F1:             0.5407561567811308\n",
      "Macro F1:             0.5427808293939542\n",
      "Weighted F1:          0.5413474693649254\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import ParameterSampler\n",
    "\n",
    "hyper_params_tune = {'max_depth' : [i for i in range(10,20,2)],\n",
    "                     'n_estimators': [int(x) for x in np.linspace(start = 200, stop = 1000, num = 11)],\n",
    "                     'min_samples_split': [2, 5, 10],\n",
    "                     'min_samples_leaf': [1, 2, 4]}\n",
    "\n",
    "params_comb = list(ParameterSampler(hyper_params_tune, n_iter = 100, random_state = 52))\n",
    "\n",
    "best_acc = 0\n",
    "\n",
    "best_sens_micro = 0\n",
    "best_sens_macro = 0\n",
    "best_sens_weight = 0\n",
    "\n",
    "best_precs_micro = 0\n",
    "best_precs_macro = 0\n",
    "best_precs_weight = 0\n",
    "\n",
    "best_f1s_micro = 0\n",
    "best_f1s_macro = 0\n",
    "best_f1s_weight = 0\n",
    "\n",
    "\n",
    "best_p = dict()\n",
    "print(ctime())\n",
    "for i in range(0, len(params_comb)):\n",
    "    \n",
    "    rfc = RandomForestClassifier(n_jobs = -1)\n",
    "\n",
    "    for k,v in params_comb[i].items():\n",
    "        setattr(rfc, k, v)\n",
    "        \n",
    "    rfc.fit(X_train, y_train)\n",
    "    y_pred = rfc.predict(X_test)\n",
    "    \n",
    "    \n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    \n",
    "    sens_micro = recall_score(y_test, y_pred, average = 'micro')\n",
    "    sens_macro = recall_score(y_test, y_pred, average = 'macro')\n",
    "    sens_weight = recall_score(y_test, y_pred, average = 'weighted')\n",
    "    \n",
    "    precs_micro = precision_score(y_test, y_pred, average = 'micro')\n",
    "    precs_macro = precision_score(y_test, y_pred, average = 'macro')\n",
    "    precs_weight = precision_score(y_test, y_pred, average = 'weighted')\n",
    "    \n",
    "    f1s_micro = f1_score(y_test, y_pred, average = 'micro')\n",
    "    f1s_macro = f1_score(y_test, y_pred, average = 'macro')\n",
    "    f1s_weight = f1_score(y_test, y_pred, average = 'weighted')\n",
    "    \n",
    "    if acc > best_acc:\n",
    "        best_p = params_comb[i]\n",
    "        best_acc = acc\n",
    "\n",
    "        best_sens_micro = sens_micro\n",
    "        best_sens_macro = sens_macro\n",
    "        best_sens_weight = sens_weight\n",
    "\n",
    "        best_precs_micro = precs_micro\n",
    "        best_precs_macro = precs_macro\n",
    "        best_precs_weight = precs_weight\n",
    "\n",
    "        best_f1s_micro = f1s_micro\n",
    "        best_f1s_macro = f1s_macro\n",
    "        best_f1s_weight = f1s_weight\n",
    "\n",
    "print(ctime())\n",
    "print(f'Model: {best_p}')\n",
    "\n",
    "print('Accuracy:            ', best_acc, end = '\\n\\n')\n",
    "\n",
    "print('Micro Recall:        ', best_sens_micro)\n",
    "print('Macro Recall:        ', best_sens_macro)\n",
    "print('Weighted Recall:     ', best_sens_weight, end = '\\n\\n')\n",
    "\n",
    "print('Micro Precision:     ', best_precs_micro)\n",
    "print('Macro Precision:     ', best_precs_macro)\n",
    "print('Weighted Precision:  ', best_precs_weight, end = '\\n\\n')\n",
    "\n",
    "print('Micro F1:            ', best_f1s_micro)\n",
    "print('Macro F1:            ', best_f1s_macro)\n",
    "print('Weighted F1:         ', best_f1s_weight)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple RASAR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:             0.5019655451497282\n",
      "\n",
      "Micro Recall:         0.5019655451497282\n",
      "Macro Recall:         0.5081249060511719\n",
      "Weighted Recall:      0.5019655451497282\n",
      "\n",
      "Micro Precision:      0.5019655451497282\n",
      "Macro Precision:      0.5049896524197746\n",
      "Weighted Precision:   0.5127183808134608\n",
      "\n",
      "Micro F1:             0.5019655451497282\n",
      "Macro F1:             0.5025635422122072\n",
      "Weighted F1:          0.5041024612726861\n"
     ]
    }
   ],
   "source": [
    "from helper_rasar_simple_multiclass import *\n",
    "\n",
    "df_rasar_train, df_rasar_test = unsuper_simple_rasar_multiclass(new_train, new_test, y_train, y_test)\n",
    "\n",
    "clf = LogisticRegression(n_jobs = -1)\n",
    "clf.fit(df_rasar_train, y_train)\n",
    "y_pred = clf.predict(df_rasar_test)\n",
    "\n",
    "print('Accuracy:            ', accuracy_score(y_test, y_pred), end = '\\n\\n')\n",
    "\n",
    "print('Micro Recall:        ', recall_score(y_test, y_pred, average = 'micro'))\n",
    "print('Macro Recall:        ', recall_score(y_test, y_pred, average = 'macro'))\n",
    "print('Weighted Recall:     ', recall_score(y_test, y_pred, average = 'weighted'), end = '\\n\\n')\n",
    "\n",
    "print('Micro Precision:     ', precision_score(y_test, y_pred, average = 'micro'))\n",
    "print('Macro Precision:     ', precision_score(y_test, y_pred, average = 'macro'))\n",
    "print('Weighted Precision:  ', precision_score(y_test, y_pred, average = 'weighted'), end = '\\n\\n')\n",
    "\n",
    "print('Micro F1:            ', f1_score(y_test, y_pred, average = 'micro'))\n",
    "print('Macro F1:            ', f1_score(y_test, y_pred, average = 'macro'))\n",
    "print('Weighted F1:         ', f1_score(y_test, y_pred, average = 'weighted'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:             0.5148572089258874\n",
      "\n",
      "Micro Recall:         0.5148572089258874\n",
      "Macro Recall:         0.5166434085030842\n",
      "Weighted Recall:      0.5148572089258874\n",
      "\n",
      "Micro Precision:      0.5148572089258874\n",
      "Macro Precision:      0.5132750905177617\n",
      "Weighted Precision:   0.5226175163610424\n",
      "\n",
      "Micro F1:             0.5148572089258874\n",
      "Macro F1:             0.5111270756828237\n",
      "Weighted F1:          0.515710712152214\n"
     ]
    }
   ],
   "source": [
    "# Random Forest\n",
    "from helper_rasar_simple_multiclass import *\n",
    "\n",
    "df_rasar_train, df_rasar_test = unsuper_simple_rasar_multiclass(new_train, new_test, y_train, y_test)\n",
    "\n",
    "clf = RandomForestClassifier(n_jobs = -1)\n",
    "clf.fit(df_rasar_train, y_train)\n",
    "y_pred = clf.predict(df_rasar_test)\n",
    "\n",
    "print('Accuracy:            ', accuracy_score(y_test, y_pred), end = '\\n\\n')\n",
    "\n",
    "print('Micro Recall:        ', recall_score(y_test, y_pred, average = 'micro'))\n",
    "print('Macro Recall:        ', recall_score(y_test, y_pred, average = 'macro'))\n",
    "print('Weighted Recall:     ', recall_score(y_test, y_pred, average = 'weighted'), end = '\\n\\n')\n",
    "\n",
    "print('Micro Precision:     ', precision_score(y_test, y_pred, average = 'micro'))\n",
    "print('Macro Precision:     ', precision_score(y_test, y_pred, average = 'macro'))\n",
    "print('Weighted Precision:  ', precision_score(y_test, y_pred, average = 'weighted'), end = '\\n\\n')\n",
    "\n",
    "print('Micro F1:            ', f1_score(y_test, y_pred, average = 'micro'))\n",
    "print('Macro F1:            ', f1_score(y_test, y_pred, average = 'macro'))\n",
    "print('Weighted F1:         ', f1_score(y_test, y_pred, average = 'weighted'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Fusion RASAR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from helper_rasar_datafusion import *\n",
    "from helper_rasar_simple_multiclass import *\n",
    "\n",
    "def create_label_rasar_multiclass(path_mortality, path_datafusion):\n",
    "    \n",
    "    db = pd.read_csv(path_mortality).drop(columns = 'Unnamed: 0')\n",
    "    df = pd.read_csv(path_datafusion).drop(columns = 'Unnamed: 0')\n",
    "    \n",
    "    df['fish'] = df['class'] + ' ' + df['tax_order'] + ' ' + df['family'] + ' ' + df['genus'] + ' ' + df['species']\n",
    "    \n",
    "    db['target'] = multiclass_encoding(db['conc1_mean'].copy())\n",
    "    df['target'] = multiclass_encoding(df['conc1_mean'].copy())\n",
    "    \n",
    "    comparing = ['test_cas', 'obs_duration_mean', 'conc1_type', 'exposure_type', 'control_type', 'media_type',\n",
    "             'application_freq_unit', 'fish']\n",
    "\n",
    "    grouped_datafusion = df.groupby(by=['endpoint', 'effect'])\n",
    "\n",
    "    db_datafusion_rasar_label = pd.DataFrame()\n",
    "\n",
    "    for g in grouped_datafusion.groups:\n",
    "        name = g[0] + '_' + g[1] + '_' + 'label'\n",
    "\n",
    "        group = grouped_datafusion.get_group(g).drop(columns = ['endpoint', 'effect'])\n",
    "    \n",
    "        db_datafusion_rasar_label[name] = db.apply(\n",
    "            lambda x: find_similar_exp(x, group, comparing), axis = 1).reset_index(drop = True)\n",
    "        \n",
    "    return db_datafusion_rasar_label\n",
    "\n",
    "db_label = create_label_rasar_multiclass('lc_db_processed.csv', 'datafusion_db_processed.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from helper_rasar_simple_multiclass import *\n",
    "\n",
    "db_df = pd.read_csv('datafusion_db_processed.csv').drop(columns = 'Unnamed: 0')\n",
    "\n",
    "db_df = pd.concat([db_df,\n",
    "                    pd.DataFrame(pd.DataFrame(db_df['pubchem2d'].values).\\\n",
    "                                 apply(lambda x: x.str.replace('', ' ').str.strip().str.split(' '), \n",
    "                                                                            axis = 1)[0].to_list(),\n",
    "                       columns = ['pub'+ str(i) for i in range(1,882)])],\n",
    "                   axis = 1)\n",
    "\n",
    "new_db_df = db_df.copy()\n",
    "new_db_df.loc[:, numerical] = minmax.transform(db_df[numerical])\n",
    "\n",
    "for ef in new_db_df.effect.unique():\n",
    "    conc = new_db_df.loc[new_db_df.effect == ef, 'conc1_mean'].copy()\n",
    "    new_db_df.loc[new_db_df.effect == ef, 'target'] = multiclass_encoding(conc.values,\n",
    "                                                                          conc.quantile([.2,.4,.6,.8]).values)\n",
    "\n",
    "categorical.remove('fish')\n",
    "new_db_df.drop(columns = categorical, inplace = True)\n",
    "\n",
    "# Simple RASAR \n",
    "db_simple_rasar_train, db_simple_rasar_test = unsuper_simple_rasar_multiclass(new_train, new_test, y_train, y_test)\n",
    "\n",
    "print('Making df rasar db')\n",
    "# DF RASAR\n",
    "db_datafusion_rasar_train = df_datafusion_rasar(new_db_df, new_train)\n",
    "db_datafusion_rasar_test = df_datafusion_rasar(new_db_df, new_test)\n",
    "\n",
    "# FINAL DB\n",
    "X_train_rasar = pd.concat([db_simple_rasar_train, db_datafusion_rasar_train,\n",
    "                           db_label.iloc[new_train.index].reset_index(drop = True)], axis = 1)\n",
    "X_test_rasar = pd.concat([db_simple_rasar_test, db_datafusion_rasar_test,\n",
    "                          db_label.iloc[new_test.index].reset_index(drop = True)], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:             0.5200023124060585\n",
      "\n",
      "Micro Recall:         0.5200023124060585\n",
      "Macro Recall:         0.5181730991481599\n",
      "Weighted Recall:      0.5200023124060585\n",
      "\n",
      "Micro Precision:      0.5200023124060585\n",
      "Macro Precision:      0.5205371742215786\n",
      "Weighted Precision:   0.5290085664796594\n",
      "\n",
      "Micro F1:             0.5200023124060585\n",
      "Macro F1:             0.5158180204562266\n",
      "Weighted F1:          0.5213142767445597\n"
     ]
    }
   ],
   "source": [
    "clf = RandomForestClassifier(n_jobs = -1)\n",
    "clf.fit(X_train_rasar, y_train)\n",
    "y_pred = clf.predict(X_test_rasar)\n",
    "\n",
    "print('Accuracy:            ', accuracy_score(y_test, y_pred), end = '\\n\\n')\n",
    "\n",
    "print('Micro Recall:        ', recall_score(y_test, y_pred, average = 'micro'))\n",
    "print('Macro Recall:        ', recall_score(y_test, y_pred, average = 'macro'))\n",
    "print('Weighted Recall:     ', recall_score(y_test, y_pred, average = 'weighted'), end = '\\n\\n')\n",
    "\n",
    "print('Micro Precision:     ', precision_score(y_test, y_pred, average = 'micro'))\n",
    "print('Macro Precision:     ', precision_score(y_test, y_pred, average = 'macro'))\n",
    "print('Weighted Precision:  ', precision_score(y_test, y_pred, average = 'weighted'), end = '\\n\\n')\n",
    "\n",
    "print('Micro F1:            ', f1_score(y_test, y_pred, average = 'micro'))\n",
    "print('Macro F1:            ', f1_score(y_test, y_pred, average = 'macro'))\n",
    "print('Weighted F1:         ', f1_score(y_test, y_pred, average = 'weighted'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rainbow Trout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from helper_knn import *\n",
    "\n",
    "db = pd.read_csv('lc_db_processed.csv').drop(columns = 'Unnamed: 0')\n",
    "\n",
    "db = pd.concat([db,\n",
    "                pd.DataFrame(pd.DataFrame(db['pubchem2d'].values).\\\n",
    "                             apply(lambda x: x.str.replace('', ' ').str.strip().str.split(' '), \n",
    "                                                                        axis = 1)[0].to_list(),\n",
    "                   columns = ['pub'+ str(i) for i in range(1,882)])],\n",
    "               axis = 1)\n",
    "\n",
    "species = pd.read_csv('C:/Users/Simone/Desktop/Utilit√† tesi magistrale/data/species.txt', sep = '\\|', engine = 'python')\n",
    "\n",
    "fm = species[species['common_name'] == 'Rainbow Trout'][\n",
    "    ['class', 'tax_order', 'family', 'genus', 'species']].values.ravel()\n",
    "\n",
    "X_train = db.loc[(db[\n",
    "    ['class', 'tax_order', 'family', 'genus', 'species']] == fm).all(axis =1)].copy().reset_index(drop=True)\n",
    "y_train = multiclass_encoding(X_train['conc1_mean'].copy())\n",
    "\n",
    "X_test = db.loc[~(db[\n",
    "    ['class', 'tax_order', 'family', 'genus', 'species']] == fm).all(axis = 1)].copy().reset_index(drop=True)\n",
    "y_test = multiclass_encoding(X_test['conc1_mean'].copy())\n",
    "\n",
    "categorical = ['test_cas', 'fish', 'smiles', 'pubchem2d', 'conc1_mean', 'obs_duration_mean',\n",
    "               'conc1_type', 'exposure_type', 'control_type', 'media_type',\n",
    "               'application_freq_unit', 'species', 'class', 'tax_order', 'family', 'genus']\n",
    "X_train.drop(columns = categorical, inplace = True)\n",
    "X_test.drop(columns = categorical, inplace = True)\n",
    "\n",
    "numerical = ['atom_number', 'bonds_number','Mol', 'MorganDensity', 'LogP',\n",
    "            'alone_atom_number', 'doubleBond', 'tripleBond', 'ring_number', 'oh_count', 'MeltingPoint', 'WaterSolubility']\n",
    "\n",
    "minmax = MinMaxScaler()\n",
    "minmax.fit(X_train[numerical])\n",
    "\n",
    "new_train = X_train.copy()\n",
    "new_train.loc[:, numerical] = minmax.transform(X_train[numerical])\n",
    "\n",
    "new_test = X_test.copy()\n",
    "new_test.loc[:, numerical] = minmax.transform(X_test[numerical])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 3 5 7 9 11 13 15 17 19 21 31 \n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAagAAAEYCAYAAAAJeGK1AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAgAElEQVR4nO3deXxU5dn/8c+VyQoBAmQBwqpABFGhRgS1amsVt1ZqXaBPF60t9XnU2trSSq12c2ux1lq7/Gzd2qpUK9JWUdxqa91YRGQz7EvCkgCyB8hy/f6YAUJIYAKTOTOT7/v1mheZe86cc40j+XLf5z73MXdHREQk0aQFXYCIiEhTFFAiIpKQFFAiIpKQFFAiIpKQFFAiIpKQFFAiIpKQFFDS5pjZj8xsQ6O2NDN73Mx2mdl5kbbXzczNbEIT+9hgZj9qtE83s2lNbPs3M3v9EPV4FI+zo/xsx0W2/9RhtrvbzMqj2WdLjmdmhWb2kZn9oolt/2BmVWbW5WiPK22DAkraPDMz4A/A5cDl7v5So02+ZWbtotzdeWZ2SgtLGNng8clI2+2N2t9r4T4D4e6VwA+Ab5jZiXvbzWwkcA3wXXffFFR9klwUUCLwAPBlYKy7/7PRa28DHYFxUexnE/ABcEtLDu7u7+x9ADMizUsbtrv71pbsM2C/A+YAv7Ow9EjbW8CjQRYmyUUBJW1aZCjqWuBL7v5ME5usAR4BvmNmWYfZnQN3Ap8xsxNiWymYWS8ze8zMlptZtZmVmdkPzSyjic07m9kkM9tuZuuaGqZsYv8FZvaQmVVG9v+GmZ3c0jrdvR74X2AEcDXwDeB44H9dS9dICyigpM0yszuAbwFfdfcnDrHpz4Aiwr9sD+dpYBEt7EVFqRBYB3wTOB/4JeEguKeJbe8DNgCfAx4D7jSza5rbsZnlAP8CzgRuAi4FtgGvmll+Swt19xnAg8DPgR8D97v73JbuR9q29KALEAlIV+D7wC/d/ZFDbejuK8zsceB7ZvZHd689xLb1ZnY38JCZ3ebui2JVsLvPAmbBvvNmbwJ7gF+Z2U3uXtdg81nufn3k52lm1oPwuaGHmtn9V4BjgUHuviJyjNeAJcCNwK1HUPKPCA+NbgZ+eATvlzZOPShpq7YC7wLXmNnQKLa/E+gN/E8U2/4FWAUcdlitJSIzDceb2YdANVBDOHByge6NNn+20fPJQF8zK2xm958i/N+j3MzSI+eN6oA3gNIjLPkawIDOwImH2VbkIAooaatqgIsIn2N6wcyOOdTGkZ7Q34AJZnbIvzeRHtbPgS+YWZ8Y1QvwPcJB+Vfg08BwwkOUANmNtq1s5nnjINsrHziL8H+Xho+xQK+WFhr53LcQ7kW9BfzGzEIt3Y+0bQooabPcfSNwHlBLeBisud7FXncAA4HLotj9w4RD4XtHVeSBLgced/cfuvvLkfM81c1s2/iz7H2+tpntNxEeMjyliceVR1DrrwmH/8+A64ATgP87gv1IG6aAkjbN3VcTnnDQlXBPqsMhtv0A+Cfhc1d2mP3uJjx54Ss032tpqRxgd6O25oYcP9vo+aXAysh1Sk15FSgBlrn7zEaP+S0p0sw+TbiHd72773b3OcBvgZ9G8Y8AkX0UUNLmRX4BXwwMAp41s8xDbH4HcBIQzWoI/4/wTLjTjrrIsJcJDxt+3czON7MngZ7NbHuymf3azM4zs58BXyBce3P+SHiG4OtmdpWZnWVmnzOze8zsumgLjMwGvB94xt0brqpxK7ALmBjtvkQUUCKAu78FXEH4PMyfmzvP5O7TCQdFNPvcSXgqeKz8gPBkh7uBx4EtwHea2fabQLfI9lcBt7r7Hw5T61mEJ0XcQfgz3gf0Yf/Fw9G4FShg/7mxvfvfAowHvmhmZ7Rgf9KGma6bExGRRKQelIiIJCQFlIiIJCQFlIiIJCQFlIiIJKSUX4svPz/f+/btG3QZIiLSjFmzZm1w94LG7SkfUH379mXmzJlBlyEiIs0ws5VNtWuIT0REEpICSkREEpICSkREEpICSkREEpICSkREElLKz+JrK6bMrmDitDLWbK6mR14O40eVMHpYcdBliYgcMQVUCpgyu4IJk+dSXVMHQMXmaiZMngugkBKRpKUhvhQwcVrZvnDaq7qmjonTygKqSETk6CmgUsCazU3f9bu5dhGRZKCASgHdOmU32d4jLyfOlYiIxI4CKsm5O4UdDr5DeVZ6GuNHlQRQkYhIbCigktw/5qxhTvlWLj6xG8V5ORhgwMCiXE2QEJGkpll8SWz91l3c9vf5DOudx6/GfIxQmgHwwGuLueelRUxfvonh/boEXKWIyJFRDypJuTvf/dsH7K6t494rhu4LJ4BrzjiGbh2zuWPqQtw9wCpFRI6cAipJTZqxmn8vqmLCBYPol9/+gNdyMkN8+7yBzFm9mec+WBtQhSIiR0cBlYRWb9rJ7c8t4PT+XfniiD5NbnPpx3oyqHtHfvbih+yurWtyGxGRRKaASjL19c63n55Dmhk/v+wk0hoM7TUUSjNuuXAQ5R9V86e3mrwXmIhIQlNAJZmH31zO9OWbuO3Tgyk+zHVOZwzI5+ySAn792mI279wTpwpFRGIj7gFlZuebWZmZLTGzm5t4/Wwz22Jm70cet0Xae5nZv8xsoZnNN7Mb41170JZUbuPn08r41KAiLju5Z1TvmXDBILbvruXXry1p5epERGIrrgFlZiHgN8AFwGBgrJkNbmLTN9x9aOTxk0hbLfBtdx8EjACua+a9Kammrp6bnppD+8wQd116AmZND+01VtKtA1eU9uJPb69g5cYdrVukiEgMxbsHNRxY4u7L3H0PMAm4JJo3uvtad38v8vM2YCHQZq5E/d3rS/mgfAt3fPYECjpktei9N507kPS0NH7+ohaPFZHkEe+AKgZWN3heTtMhM9LM5pjZC2Z2fOMXzawvMAx4t6mDmNk4M5tpZjOrqqqOvuqAzavYwv2vLuaSoT248ITuLX5/Ycdsvn7WMTw/dy2zVn7UChWKiMRevAOqqXGpxleSvgf0cfeTgF8DUw7YgVku8AzwTXff2tRB3P1Bdy9199KCgoIYlB2cXTV13PTU+3TNzeQnnxlyxPsZd+YxFHbI4o7nF+jiXRFJCvEOqHKgV4PnPYE1DTdw963uvj3y81Qgw8zyAcwsg3A4Pe7uk+NTcrB++coiFq3fzt2fO5FO7TKOeD/tMtP59nkDeW/VZl6cty6GFYqItI54B9QMYICZ9TOzTGAM8I+GG5hZN4vMADCz4ZEaN0baHgIWuvu9ca47EDNXbOLB/yxj7PDefKKk8Kj3d9nJvSgp6sDdL37Intr6GFQoItJ64hpQ7l4LXA9MIzzJ4Sl3n29m15rZtZHNLgPmmdkc4H5gjIfHpE4Hvgh8ssEU9AvjWX887dhdy7efnkPPzjncctGgmOwzlGZMuPA4Vm7cyV/e0cW7IpLY4r6aeWTYbmqjtt83+PkB4IEm3vdfmj6HlZLuemEhqzbtZNLXRpCbFbuv6ayBBXx8QD73v7aYz32s51ENG4qItCatJJGA/rOoir+8s4prTu/Hqcd0jem+zYwJFwxiS3UNv3ldF++KSOJSQCWYLdU1fPdvH9C/MJfvtNIdcQf36MhlH+vJo2+uYPWmna1yDBGRo6WASjA//sd8qrbv5t4rTiI7I9Rqx/n2eSWkpcHEabp4V0QSkwIqgbw4bx2TZ1dw3Sf6c2LPvFY9VrdO2Yz7+DH8Y84a3l+9uVWPJSJyJBRQCWLD9t3c8uxchhR35IZP9o/LMceddSz5uZnc+bzuvCsiiUcBlQDcnVuencu2XbXce8VQMkLx+Vpys9L51rkDmb5iEy8tWB+XY4qIREsBlQCmvF/BtPnr+fZ5AxlY1CGux76ytBf9C3O5+4UPqanTxbsikjgUUAFbu6Wa2/4+n1P6duarHz8m7sdPD6Xx/QuPY/mGHTw5fVXcjy8i0hwFVIDcne/+7QNq65x7Lj+JUDO3b29tnygp5LRju3LfK4vZuqsmkBpERBpTQAXo8XdX8cbiDXz/okH06do+sDrMjO9fOIiPdu7hd68vDawOEZGG4r7UUVs3ZXYFE6eVsWZzNQAlRbl84dTeAVcFQ4o78dmhxTz03+V8YUQfivNygi5JRNo49aDiaMrsCiZMnkvF5mqc8I2wVm7cyd/fX3O4t8bFt0eVYMA9unhXRBKAAiqOJk4ro7qm7oC2XbX1CbOaQ3FeDtec0Y9nZ1cwr2JL0OWISBungIqjvcN60bYH4X/PPpau7TO5XXfeFZGAKaDiqEcz53Waaw9Ch+wMvvmpAbyzbBOvfVgZdDki0oYpoOJo/KgSGs8kz8kIMb6VVi0/UmOG9+aYgvbcOXUhtbp4V0QCooCKo6G98qh36JidjhE+53PXpScwelhx0KUdICOUxs3nH8fSqh1MmrE66HJEpI3SNPM4mjRjNaE045WbzqKwY3bQ5RzSuYOLGN6vC/e9sojRw4pjeldfEZFoqAcVJzV19fxtVjmfPK4w4cMJwhfv3nLhIDZs38PIO1+l383Pc/rdrzFldkXQpYlIGxH3gDKz882szMyWmNnNTbx+tpltMbP3I4/bGrz2sJlVmtm8+FZ99F5duJ4N23czdnivoEuJ2vINOwiZsW13LQ5UbK5mwuS5CikRiYu4BpSZhYDfABcAg4GxZja4iU3fcPehkcdPGrQ/Cpzf+pXG3pPTV9O9UzZnDSwMupSoTZxWRl2jqebVNXUJc92WiKS2ePeghgNL3H2Zu+8BJgGXRPtmd/8PsKm1imst5R/t5D+Lq7i8tFdgC8IeiWS4bktEUle8A6oYaDgtrDzS1thIM5tjZi+Y2fEtPYiZjTOzmWY2s6qq6khrjZmnZpYDcEVpz4AraZlkuG5LRFJXvAOqqe5D4+UK3gP6uPtJwK+BKS09iLs/6O6l7l5aUFBwBGXGTl298/TM1Zw5oICendsFWktLjR9VQk5G6IC27Iy0hLtuS0RSU7wDqhxoOEugJ3DASqnuvtXdt0d+ngpkmFl+/EqMrX8vqmTtll1JNTlir9HDirnr0hMOWNn8ytJeCXfdloikpnhf3DIDGGBm/YAKYAzw+YYbmFk3YL27u5kNJxyiG+NcZ8w8OX01+blZnDOoKOhSjsjoYcWMHlZMXb3ziXteZ96arUGXJCJtRFx7UO5eC1wPTAMWAk+5+3wzu9bMro1sdhkwz8zmAPcDYzyyaqmZPQm8DZSYWbmZXRPP+luqcusuXvuwkstO7klGKLkvOQulGV8+rS+zVn7EB+Wbgy5HRNqAuC8PEBm2m9qo7fcNfn4AeKCZ945t3epi6+lZ5dTVO2NOSb7hvaZcXtqTe18q49E3V3DvlUODLkdEUlxy/7M+gdXXO5NmrGLkMV3pmx/c7dxjqWN2BpeX9uKfH6yhctuuoMsRkRSngGolby3dyOpN1YxJwskRh/Ll0/pSU+c8/s6qoEsRkRSngGolT05fRV67DEYd3y3oUmKqX357PlFSwOPvrmR3bd3h3yAicoQUUK1g4/bdvLRgHZcO60l2o+uIUsHVp/djw/Y9PDdnbdCliEgKU0C1gmfeK6emzpPy2qdofHxAPv0Lc3n0rRW6LbyItBoFVIy5O5NmrObkPp0ZUNQh6HJahZlx1Wl9mVuxhVkrPwq6HBFJUQqoGJu+fBPLqnakzNTy5lz6sWI6ZqfzyJsrgi5FRFKUAirGJs1YTYesdC46sXvQpbSqdpnpjB3emxfnr9Pq5iLSKhRQMbRlZw1T567lkmE9aJeZ+rdI/+LIPrg7f3p7ZdCliEgKUkDF0LOzy9ldW8+YU3oHXUpc9OzcjvMGd2PSjFVU79GUcxGJLQVUjOydHHFCcSeGFHcKupy4ufr0vmzeWcOU93UbeBGJLQVUjLy/ejMfrtuWcitHHM7wfl0Y3L0jj7y5XFPORSSmFFAxMmn6anIyQnzmpB5BlxJXZsbVp/dl0frtvLU0ae+KIiIJSAEVA9t31/LPD9bw6ZO60yE7I+hy4u7TJ/Wga/tMHnlzedCliEgKUUDFwD/eX8POPXWMGd42Jkc0lp0R4vOn9ubVDytZuXFH0OWISIpQQMXApBmrKCnqwLBeeUGXEpgvjOhDyIzH3tKUcxGJDQXUUZq/ZgsflG9hzPBemFnQ5QSmqGM2F53Ynadnrmb77tqgyxGRFKCAOkqTpq8mMz2Nzw4rDrqUwF19ej+27a7lbzNXB12KiKSAqALKzC42M4VZI9V76pjyfgUXDulGXrvMoMsJ3NBeeQztlcdjb6+kvl5TzkXk6EQbOn8HKszsZ2Y26GgOaGbnm1mZmS0xs5ubeP1sM9tiZu9HHrdF+954e37uWrbtqm2zkyOacvXpfVm+YQf/XlQVdCkikuSiDahjgQeBK4B5Zva2mX3NzDq25GBmFgJ+A1wADAbGmtngJjZ9w92HRh4/aeF742bS9FUck9+eU/t1CbKMhHLhCd0p6pjFw5pyLiJHKaqAcvcV7v5Dd+8HnAssAX4JrDWzP5vZJ6I83nBgibsvc/c9wCTgkji8N+YWr9/GzJUfceUpbXtyRGMZoTS+OKIPbyzewJLKbUGXIyJJrMXnldz9NXf/IjAQmAX8D/CKmS03s2+Z2aGW8S4GGp5BL4+0NTbSzOaY2QtmdnwL34uZjTOzmWY2s6qqdYaaJs1YTUbI+NzJPVtl/8ls7PDeZKan6V5RInJUWhxQZnaWmT0KlAFDCA+7nQc8DfwY+NOh3t5EW+Oz6e8Bfdz9JODXwJQWvDfc6P6gu5e6e2lBQcEhyjkyu2vrmPxeOecOLiI/Nyvm+092XXOzuOSkHkx+r4ItO2uCLkdEklS0s/j6mNltZrYUeA3oBYwDurv7De7+qrt/F/gyhx52K4+8d6+ewJqGG7j7VnffHvl5KpBhZvnRvDdeps1fz0c7a9rMbTWOxNWn96O6po6/zlwVdCkikqSi7UEtA74GPAH0d/dz3P1Jd9/daLv5wPRD7GcGMMDM+plZJjAG+EfDDcysm0VO6pjZ8EiNG6N5b7xMmr6Knp1zOKN/fhCHTwqDe3Tk1H5deOytldTW1QddjogkoWgD6tOEh91udfdmp2e5+yJ3b3bChLvXAtcD04CFwFPuPt/MrjWzayObXUZ4puAc4H5gjIc1+d4o64+ZlRt38NbSjVxZ2ou0NE2OOJSrT+9HxeZqXlm4PuhSRCQJRXtf8jeAImBt4xfMrDuwbe+w3OFEhu2mNmr7fYOfHwAeiPa98TZpxmrSDC4vbVv3fToS5w4uojgvh4ffXMH5Q7oHXY6IJJloe1APAT9p5rUfAX+MSTUJrqaunqdnlvPJ4wrp1ik76HISXijN+PJpfZi+fBPz12wJuhwRSTLRBtSZwPPNvDY18nrKe3VhJRu279bkiBa4srQ3ORkhHtWUcxFpoWgDqhOws5nXdgGdY1NOYps0YxVFHbM4uyT2U9dTVad2GXzu5GL+PmcNG7c3nlMjItK8aANqMXBRM69dCCyNTTmJq2JzNf9eVMUVpb1ID2nd3Ja46rR+7Kmt54l3NeVcRKIX7W/aXwPXm9lEMzvezLpE/vw5cB3wq9YrMTE8NSO8iMUVmhzRYv0LczlzYAF/fmcle2o15VxEohPtWnx/AH4I/B/wAVAV+fM64AeR11NWXb3z9MzVnNE/n15d2gVdTlK6+rS+VG7bzQvzDpoIKiLSpKjHqtz9dqAH4aG+L0X+7OHud7dSbQnjP4uqWLNlF2N1W40jdtbAAo7Jb6/1+UQkai06meLuW9z9RXd/PPJnm5g7/OT0VeTnZvKpQUVBl5K00tKML5/Wl/dXb2b2qo+CLkdEkkC0F+oSWX7odMKrmB90EZC7/zaGdSWMyq27ePXDSr768X5kpmtyxNH43Mk9uWdaGY+8uYJhvdvExE8ROQpRBZSZFQGvEr5RoLN/ZfGGq4mnZEA9PaucunrXtU8xkJuVzhWn9OKxt1bw/QsH6WJnETmkaLsEvwC2EF5N3IBTgb7ArYSnoA9sjeKCNGV2Bafd/SoTp5WRmZ7GnNWbgy4pJXx5ZF/q3Hn83ZVBlyIiCS7agDqLcEjtnYJl7r7K3e8E/kKK9Z6mzK5gwuS5rNm8C4A9tfVMmDyXKbMrAq4s+fXu2o5zjiviiXdXsaumLuhyRCSBRRtQeUCVu9cDW4HCBq+9BZwW68KCNHFaGdWNfnlW19QxcVpZQBWllq+c3peNO/Yw4q5X6Xfz85x+92sKfxE5SLQBtRzYuxz1fMK3ed/r08CmWBYVtDWbq1vULi2zfusuDNi8swYnvEqHeqgi0li0ATWV8G3dAW4HPmdm5Wa2HPgG4ZUmUkaPvJwWtUvL3PPSogNm14B6qCJysGhXkrjZ3b8a+fkFwkN6jwHPAhe7+z2tV2L8jR9VQk5G6IC2nIwQ40eVBFRRalEPVUSicdhp5maWBXwHeM7d5wC4+0xgZivXFpjRw4qB8LmoNZur6ZGXw/hRJfva5ej0yMuhookwUg9VRBo6bEC5+24zuwX4bxzqSRijhxUrkFrJ+FElTJg894CJKNkZaeqhisgBoj0H9S5wcmsWIm3H6GHF3HXpCRQ36DGdN7hI/yAQkQNEG1DfBf7XzK43s2PMrL2ZtWv4iPaAZna+mZWZ2RIzu/kQ251iZnVmdlmDthvNbJ6ZzTezb0Z7TEk8o4cV8+bNn2TF3RdxznGF/OvDKjbohoYi0kBLelDHAvcTXjliK7Ct0eOwzCwE/Aa4gPCySWPNbHAz2/0MmNagbQjwNWA4cBJwsZkNiLJ+SWDfv2gQ1TV13PvyoqBLEZEEEu1isV+Bg2YGH4nhwBJ3XwZgZpOAS4AFjba7AXgGOKVB2yDgHXffGXnvv4HPAj+PQV0SoGMLcvnSyL48+tZyvjiiD4O6dwy6JBFJAFEFlLs/GqPjFQOrGzwvJ7yu3z5mVkw4eD7JgQE1D7jDzLoC1YRvNd/kTEIzGweMA+jdW4u8JoMbzxnA5Nnl3P78Av5yzamEF88XkbYs3vePaOq3TuOe2X3A99z9gLWG3H0h4WG/l4EXgTlAbVMHcfcH3b3U3UsLCgqOvmppdZ3aZfCtTw3kzSUbeWVhZdDliEgCiCqgzKzKzCoP9YjyeOWEV0TfqyewptE2pcAkM1sBXAb81sxGA7j7Q+7+MXc/k/DySoujPK4kgc+f2pv+hbnc8fwC9tTWB12OiAQs2nNQv+Hgnk4XwsNwHYGHotzPDGCAmfUDKoAxwOcbbuDu/fb+bGaPEr5AeErkeaG7V5pZb+BSYGSUx5UkkBFK4wcXDeKqR2bwp7dX8NWPHxN0SSISoGjPQf2oqfbIXXafopmhtib2U2tm1xOenRcCHnb3+WZ2beT13x9mF89EzkHVANe5u+4dnmLOLink7JICfvXqYj47rJiuuVlBlyQiATH3o5ucZ2ajgEfcvUdsSoqt0tJSnzkzZVdlSklLKrcx6r43GDu8F7ePPiHockSklZnZLHcvbdwei0kSxwCZMdiPCAD9CzvwxRF9eOLdVZSti+oSOxFJQVEN8ZnZ/zXRnEn42qT/AZ6OZVEiN54zgGdnV3D78wv401eGa9q5SBsU7SSJB5po2014Vt5vgR/HrCIRoHP7TL75qQH8+J8L+FdZJZ88rijokkQkzqK9H1RaE48cdx/g7t919x2tXai0PV8Y0YdjCtpz+3MLqanTtHORtibeF+qKRG3vtPNlG3bw57dXBl2OiMRZtBfq3mFm/6+Z135vZj+NbVkiYZ8oKeTjA/K575VFfLRjT9DliEgcRduDGgu80cxrb9DoYluRWDEzbr14MNt313LfK1rtXKQtiTagehBe+aEpayKvi7SKgUUd+J9T+/CXd1exeL2mnYu0FdEG1DrgY8289jGgKjbliDTtW+cOpF1miNufXxh0KSISJ9EG1FPAbWZ2UcNGM7sQuBWYFOvCRBrq0j6TG88ZwL8XVfGvMq12LtIWRBtQtxG+q+4/Iyubf2BmVcA/gbcJh5RIq/rSyL70y2/P7c8t0LRzkTYg2uugdrn7eYRv1f4Q4bB6CDjf3S9w992tWKMIAJnpadxy4SCWVu3g8Xc07Vwk1UW7kgQA7j6N8ErkIoE4Z1AhZ/TP55evLGb0sGLy2mkZSJFUFe11UGPMbHwzr33HzK6IbVkiTTMzfnDxILbtquG+V3S/SpFUFu05qJuBXc28thOYEJtyRA7vuG4dGTO8N39+ZyVLKjXtXCRVRRtQA4B5zby2MPK6SNzcdO5A2mWEuEPTzkVSVrQBtRPo2cxrvQivbC4SN/m5WdxwTn/+VVbF65p2LpKSog2oV4BbzaywYaOZFQC3AC/FujCRw/nyaX3p07Udtz+/kFpNOxdJOdEG1PeAXGCpmT1tZveb2dPAUqAd8N1oD2hm55tZmZktMbObD7HdKWZWZ2aXNWj7lpnNN7N5ZvakmWVHe1xJPVnpIb5/4SCWVG7niemrgi5HRGIs2uugVgEnEb5xYS/C10P1An4NDCW8FNJhmVkI+E3k/YOBsWY2uJntfkaDKe1mVgx8Ayh19yFACBgTzXEldZ03uIiRx3Tlly8vYsvOmqDLEZEYivp+UO5e5e4T3H2Euw8ATgNeBe4myoAChgNL3H2Zu+8hvETSJU1sdwPwDND45EI6kGNm6YR7bmuirV9S097VzjdX13D/a5p2LpJKWnzDQjM71czuI3y795eB0US/Fl8xsLrB8/JIW8P9FwOfBX7fsN3dK4B7gFXAWmCLu+vclzC4R0fGnNKLx95awbKq7UGXIyIxEu2FukMiNy1cCrwFfB0oAm4Curv7dVEez5po80bP7wO+5+51jWroTLi31Y/w7T3am9kXmql3nJnNNLOZVVVaaL0tuOncErIzQtw5VdPORVJFs0sdmdkxhM/xjCV8vqiWcI/pNuDfhHsys929tgXHKyd87mqvnhw8TFcKTDIzgHzgQjOrBTKA5e5eFalvMuFhxr80Poi7Pwg8CFBaWto4ACUFFXTI4rpP9OdnL37IyT99mU079tAjL4fxo0oYPaz48DsQkYRzqLX4lhDu3bxLuMf0jLt/BGBmnY7weDOAAWbWj/ANEMfQ6G687t5v789m9ijwnLtPMbNTgRFm1kWZqaoAABRWSURBVA6oBs4BZh5hHZKC8nMzMWBj5NbwFZurmTB5LoBCSiQJHWqIbyXhIbkhwNnAaZHJCUcs0tu6nvDsvIXAU+4+38yuNbNrD/Ped4G/Ae8BcyO1P3g09Uhque+VxQeNF1fX1DFxWlkg9YjI0Wk2cNy9n5mNJNzDuSzy50eRobUXOPjcUVTcfSowtVHb75vZ9qpGz38I/PBIjiupb83m6ibbKzZX8485azjnuELaZx3Vv7FEJI4O+bfV3d8G3jazGwkPqY0FPgdcQzigvmZmO91dQ20SuB55OVQ0EVJpBt94cjbZGWmcc1wRF5/YnU8cV0h2RiiAKkUkWubeso6QmWUCFxI+f3QxkAMscvdBsS/v6JWWlvrMmcrPtmDK7AomTJ5Ldc3+CaA5GSHuHD2EHp1zeO6Dtbwwby0btu+hXWaITw0Kh9VZJQVkpSusRIJiZrPcvfSg9pYGVKOdtid8HdQYd//0UdTXahRQbcuU2RVMnFbGms3VTc7iq62r593lm3jug7W8OG8tH+2soUNWOuceX8SnT+zB6f3zyUxv8eWBInIUWiWgkoECSppTU1fPW0s38tycNUybv46tu2rplJPB+cd346ITu3PasV1JD4XD6nDBJyJHTgElcgh7aut5Y3EVz32wlpcXrGf77lq6tM/k/CHdyGuXwSP/XU51zf4V03MyQtx16QkKKZEYaC6gNKVJBMhMT+OcQUWcM6iIXTV1/HtROKyefa/igHNae+2dvq6AEmk9CiiRRrIzQow6vhujju9G9Z46Bt32YpPbNTetXURiQ2eDRQ4hJzNEcV5Ok6/1aKZdRGJDASVyGONHlZDT6JopA75yet9A6hFpKxRQIocxelgxd116AsV5ORjhhWmzM9L443+Xs3zDjqDLE0lZmsUncgQWrNnKFx56l4yQ8cTXRnBsQW7QJYkkreZm8akHJXIEBvfoyJNfG0FdvTPmwXdYvH5b0CWJpBwFlMgRKunWgUnjRgAw5sF3KFunkBKJJQWUyFHoXxgOqfSQMebBt1mwZmvQJYmkDAWUyFE6tiCXv44bSU5GiM//8R3mVWwJuiSRlKCAEomBvvnt+evXR9I+M53P/+Ed5qzeHHRJIklPASUSI726tOOvXx9Bp3YZfOGP7/Leqo+CLkkkqSmgRGKoZ+d2/HXcSLrmZvKlh6Yzc8WmoEsSSVoKKJEY65GXw6RxIynskMWXHp7Ou8s2Bl2SSFKKe0CZ2flmVmZmS8zs5kNsd4qZ1ZnZZZHnJWb2foPHVjP7ZvwqF4let07ZTBo3gh55OVz1yAzeWrIh6JJEkk5cA8rMQsBvgAuAwcBYMxvczHY/A6btbXP3Mncf6u5DgZOBncCzcSlc5AgUdszmya+NoHeXdlz96AzeWFwVdEkiSSXePajhwBJ3X+bue4BJwCVNbHcD8AxQ2cx+zgGWuvvK1ilTJDYKOmTxxNdOpV9+e655bCavlzX3v7SINBbvgCoGVjd4Xh5p28fMioHPAr8/xH7GAE/GvDqRVtA1N4snvzaCAYW5jPvTLF5duD7okkSSQrwDyppoa7xa7X3A99z94NuYAmaWCXwGeLrZg5iNM7OZZjazqkrDKhK8zu0zeeKrIziueweu/cssps1fF3RJIgkv3gFVDvRq8LwnsKbRNqXAJDNbAVwG/NbMRjd4/QLgPXdv9p+h7v6gu5e6e2lBQUFsKhc5Sp3aZfDna07l+B6duO7x95g6d23QJYkktHjf8n0GMMDM+gEVhIfqPt9wA3fvt/dnM3sUeM7dpzTYZCwa3pMk1Skngz9fM5yrHpnBDU/O5p1lG3l1YSVrNlfTIy+H8aNKGD2s+PA7EmkD4tqDcvda4HrCs/MWAk+5+3wzu9bMrj3c+82sHXAuMLl1KxVpPR2yM3jsK8Pp06Udf3p7JRWbq3GgYnM1EybPZcrsiqBLFEkI8e5B4e5TgamN2pqcEOHuVzV6vhPo2mrFicRJblY61TUHn2atrqlj4rQy9aJE0EoSIoFZt2VXk+1rNlfHuRKRxKSAEglIj7ycFrWLtDUKKJGAjB9VQk5G6KD2Ecd0CaAakcSjgBIJyOhhxdx16QkU5+VgQI9O2Qzp0ZFn3qvgof8uD7o8kcDFfZKEiOw3eljxARMiaurq+caTs/npcwuoq69n3JnHBlidSLDUgxJJIBmhNO4fO4yLTuzOnVM/5Df/WhJ0SSKBUQ9KJMFkhNL41ZVDSU8zJk4ro7bOufFTA4IuSyTuFFAiCSg9lMa9VwwlPS2NX76yiLr6er517kDMmlrOUiQ1KaBEElQozZh42Ymkpxn3v7aE2npn/KgShZS0GQookQSWlmbcdekJhELGb19fSm29M+GC4xRS0iYooEQSXFqaccfoIaSnGQ/+Zxk1dfXcdvFghZSkPAWUSBIwM378meNJT0vj4TeXU1fv/Pgzx8c1pKbMrmDitDKtvC5xo4ASSRJmxq0XDyI9FO5J1dY7t18yhLS01g+pKbMrmDB57r4FbveuvA4opKTVKKBEkoiZMeGC40hPC5+Tqqtz7rr0hFYPqYnTyg5afb26po47pi7kjAH5dGmXGZeglLZFASWSZMyM8aNKSA+lcf+ri6mpr2fiZScRaoWAqK2rZ/ryTVQ0s8J61bbdlN7+CpmhNIo6ZdGtYzbdOuXQvVM2RR2z6d4pm26dwn8W5GaRHjp4bQANHUpzFFAiScjMuOncgaSnGfe+vIi6eucXl5/UZAC01J7aet5auoEX5q7j5YXr2bRjT7PbdmmfyY3nDGDtll2s21LN2i27mFu+mZfm72J3bf0B26YZFHTICgdYx3Bwbdy+mxfnr6OmzgENHcqBFFAiSewb5wwIXy81rYy6eueXVw4l4whCaldNHf9ZVMWL88KhtG1XLblZ6XzyuEIuGNKNbbtq+OE/FhwwzJeTEeK2iwc3GSTuzuadNazbuot1W3btC7B1W8M/L63azptLN7BtV+1B762uqWPC5Lms3bKLkm65DCjsQHFejoYQ2yAFlEiSu+4T/ckIGXdO/ZC6eudXY4aRmX74kNqxu5bXy6qYOm8t//qwkp176uiUk8Go47txwZBunN4/n+wGtwPJTA9FPRRnZnRun0nn9pkM6t6x2Rr63fw83kR7dU0dP3vxw33P22WGGFCYy8CiDgws6sCAovDP3Ttla7p9ClNAiaSAcWceSygtjZ8+t4DaJ95j1OAifvnK4oPCZOuuGl5duJ4X5q7j34uq2F1bT9f2mVwytJgLhnRj5LFdm+2BNV55PRZ65OU0eX6rOC+HqTd+nCWV2yhbt51F67exuHIbry+q4ulZ5fu265CVvi+sBhR1oKSoAwOLcinokKXgSgHm3tS/X1rxgGbnA78CQsAf3f3uZrY7BXgHuNLd/xZpywP+CAwBHPiKu799qOOVlpb6zJkzY/gJRBLXn95ewW1/n0+aQX2Dv9oZIaN/QS5LqrZTU+cUdczigiHdOX9IN07p26VVJlhEo/H0dQgPHd516QnNhuFHO/awaP02FlVuZ/H6bZSt28biyu0HnCvrlJPBwKLcfaG1N8Tyc7Na/TNJy5nZLHcvPag9ngFlZiFgEXAuUA7MAMa6+4ImtnsZ2AU83CCgHgPecPc/mlkm0M7dNx/qmAooaWuG/vglNlfXHNQeSjO+cnpfzh/SnWG98hLmnE6sZvFt2L47HFzr9ofXovXb2dLgv0WX9pkMbNDjGhgZNuzcPjOWH0laqLmAivcQ33BgibsvixQ1CbgEWNBouxuAZ4BT9jaYWUfgTOAqAHffAzQ/vUikjdrSRDgB1Nc7t1w0OM7VHF6shg7zc7PIz83itGPz97W5O5XbIsG1PtLjWr+Nye9VsH33/gkaBR2ywj2uwg6UdOuwr/fVMTvjqOuSIxfvgCoGVjd4Xg6c2nADMysGPgt8kgYBBRwDVAGPmNlJwCzgRnff0fggZjYOGAfQu3fvWNYvkvCaO6/TIy8ngGqCZWYUdQxfk/XxAQX72t2dtVt2RYJrf3g9NXM1O/fsH27s1jGbgd3297QGRIIrN0un7+Mh3v+VmxpTaDzGeB/wPXeva3SSMx34GHCDu79rZr8CbgZuPWiH7g8CD0J4iC8WhYski/GjSpo8rzN+VEmAVSUWM6NHXg498nI4u6RwX3t9vVOxufqgHtefl2084Lqu4rycfUOFex/9C3PJyQw1dTg5QvEOqHKgV4PnPYE1jbYpBSZFwikfuNDMaglPmCh393cj2/2NcECJSAN7h8u0OkPLpaUZvbq0o1eXdpwzqGhfe129s3rTzgN6XIvWb+PNJRvZUxcOLjPo1bldJLD297iOLcg9YLq+RC/ekyTSCU+SOAeoIDxJ4vPuPr+Z7R8FnmswSeIN4KvuXmZmPwLau/v4Qx1TkyREpLXU1tWzYuPOfRMyFlWGJ2ks37CD2sg0yjSDvl3bHzQdvl9++6iuV2sLEmKShLvXmtn1wDTC08wfdvf5ZnZt5PXfH2YXNwCPR2bwLQOubtWCRUQOIT2URv/CXPoX5nLBCfvb99TWs2Ljjv2zCiPh9fKC9fum/6enGX3z2zcaKsylT9f2R7QaSCqK+3VQ8aYelIgkil01dSyr2sHiygOHCldt2sneX8UZIePYgtx90+AHFIVnFvbu0i6w69VaW0L0oERE2rLsjBCDe3RkcI8Dl3+q3lPH0qpwWJWt38bi9duZveoj/jln/yn6rPQ0ji3IDfe4unVgYGG419Wzc+quU6iAEhEJWE5miCHFnRhS3OmA9h27a1lcGVnqKdLjenf5Jqa8vz+4cjJC4envhfsnZwzs1oEeKbBOoQJKRCRBtc9KZ2ivPIb2yjugfeuuGhY3mAa/eP123lhcxTPv7V+nMDcrnf6FuQdNhy/qmDzrFCqgRESSTMfsDE7u05mT+3Q+oH3zzj37zmvt7XG9urCSp2aWN3hv+v6lnhqEV35uZsIFlyZJiIikuI3bd+8LrkWRHteiym1s3rl/WazO7TL2hVbJvgDrQJdm1imM5Z2QNUlCRKSN6pqbxcjcLEYe23Vfm7tTtW1/cC2uDK8M//fZa9jWYJ3C/NzMg+7DtXj9Nn763MJ9q5W01p2QFVAiIm2QmVHYMZvCjtmcMeDABXbXbd0VDq512/bd2uTpmavZ0WCdwsaqa+qYOK1MASUiIq3DzOjeKYfunXI4a+D+BXbr6501W8LrFH7l0aZPm6xpYpHio6GAEhGRw0pLM3p2bkfPzu0ojtOK+VpPQ0REWmT8qBJyGi2A2xor5qsHJSIiLRKvFfMVUCIi0mKxuhPyoWiIT0REEpICSkREEpICSkREEpICSkREEpICSkREElLKLxZrZlXAykbN+cCGAMqJB3225JSqny1VPxfos8VSH3cvaNyY8gHVFDOb2dTKualAny05pepnS9XPBfps8aAhPhERSUgKKBERSUhtNaAeDLqAVqTPlpxS9bOl6ucCfbZW1ybPQYmISOJrqz0oERFJcAooERFJSG0qoMzsfDMrM7MlZnZz0PXEmpmtMLO5Zva+mTV9y8skYWYPm1mlmc1r0NbFzF42s8WRPzsHWeORaOZz/cjMKiLf2/tmdmGQNR4pM+tlZv8ys4VmNt/Mboy0p8L31txnS/rvzsyyzWy6mc2JfLYfR9oD/97azDkoMwsBi4BzgXJgBjDW3RcEWlgMmdkKoNTdk/7iQTM7E9gO/Mndh0Tafg5scve7I//A6Ozu3wuyzpZq5nP9CNju7vcEWdvRMrPuQHd3f8/MOgCzgNHAVST/99bcZ7uCJP/uzMyA9u6+3cwygP8CNwKXEvD31pZ6UMOBJe6+zN33AJOASwKuSZrh7v8BNjVqvgR4LPLzY4R/QSSVZj5XSnD3te7+XuTnbcBCoJjU+N6a+2xJz8O2R55mRB5OAnxvbSmgioHVDZ6XkyL/gzXgwEtmNsvMxgVdTCsocve1EP6FARQGXE8sXW9mH0SGAJNuCKwxM+sLDAPeJcW+t0afDVLguzOzkJm9D1QCL7t7QnxvbSmgrIm2VBvfPN3dPwZcAFwXGU6SxPc74FhgKLAW+EWw5RwdM8sFngG+6e5bg64nlpr4bCnx3bl7nbsPBXoCw81sSNA1QdsKqHKgV4PnPYE1AdXSKtx9TeTPSuBZwsOaqWR95FzA3nMClQHXExPuvj7yC6Ie+ANJ/L1FzmE8Azzu7pMjzSnxvTX12VLpuwNw983A68D5JMD31pYCagYwwMz6mVkmMAb4R8A1xYyZtY+cvMXM2gPnAfMO/a6k8w/gy5Gfvwz8PcBaYmbvL4GIz5Kk31vkZPtDwEJ3v7fBS0n/vTX32VLhuzOzAjPLi/ycA3wK+JAE+N7azCw+gMgU0PuAEPCwu98RcEkxY2bHEO41AaQDTyTz5zOzJ4GzCS/7vx74ITAFeAroDawCLnf3pJpw0MznOpvwEJEDK4Cv7x37TyZmdgbwBjAXqI80f5/wuZpk/96a+2xjSfLvzsxOJDwJIkS40/KUu//EzLoS8PfWpgJKRESSR1sa4hMRkSSigBIRkYSkgBIRkYSkgBIRkYSkgBIRkYSkgBJJcJEVszc0akszs8fNbJeZnRdUbSKtKT3oAkSkZSIXjf4BuBz4nLu/FHBJIq1CASWSfB4gfGX/le7+z6CLEWktCiiRJGJmvwCuBb7o7s8EXY9Ia1JAiSQJM7sD+BZwjbs/EXQ9Iq1NkyREkkNXwmu/3efujwRdjEg8KKBEksNWwouuXmNmQ4MuRiQeFFAiyaEGuIjwPcxeiKxeL5LSFFAiScLdNxK+z1ctMM3MkvrW6SKHo4ASSSLuvprw3U67Eu5JdQi4JJFWo4ASSTLuPh+4GBgEPBu5Q7RIylFAiSQhd38LuAI4C/izmenvsqQc3VFXREQSkv7VJSIiCUkBJSIiCUkBJSIiCUkBJSIiCUkBJSIiCUkBJSIiCUkBJSIiCUkBJSIiCen/AzncS3H2DSyPAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "metrics = pd.DataFrame(index = ['Acc',\n",
    "                                'Sens (micro)', 'Sens (macro)', 'Sens (weighted)',\n",
    "                                'Prec (micro)', 'Prec (macro)', 'Prec (weighted)',\n",
    "                                'F1 (micro)', 'F1 (macro)', 'F1 (weighted)'])\n",
    "for k in [1,3,5,7,9,11,13,15,17,19,21,31]:\n",
    "    print(k, end = ' ')\n",
    "    knn = KNeighborsClassifier(n_neighbors = k, n_jobs = -1)\n",
    "    knn.fit(new_train, y_train)\n",
    "    y_pred = knn.predict(new_test)\n",
    "    \n",
    "    metrics = pd.concat([ metrics,\n",
    "                         pd.DataFrame([accuracy_score(y_test, y_pred),\n",
    "                                       \n",
    "                                       recall_score(y_test, y_pred, average = 'micro'),\n",
    "                                       recall_score(y_test, y_pred, average = 'macro'),\n",
    "                                       recall_score(y_test, y_pred, average = 'weighted'),\n",
    "                                       \n",
    "                                       precision_score(y_test, y_pred, average = 'micro'),\n",
    "                                       precision_score(y_test, y_pred, average = 'macro'),\n",
    "                                       precision_score(y_test, y_pred, average = 'weighted'),\n",
    "                                       \n",
    "                                       f1_score(y_test, y_pred, average = 'micro'),\n",
    "                                       f1_score(y_test, y_pred, average = 'macro'),\n",
    "                                       f1_score(y_test, y_pred, average = 'weighted')], \n",
    "                                                index = ['Acc',\n",
    "                                'Sens (micro)', 'Sens (macro)', 'Sens (weighted)',\n",
    "                                'Prec (micro)', 'Prec (macro)', 'Prec (weighted)',\n",
    "                                'F1 (micro)', 'F1 (macro)', 'F1 (weighted)'])], axis = 1)\n",
    "\n",
    "print('')\n",
    "metrics = metrics.T.reset_index(drop=True)\n",
    "metrics['K'] = pd.Series([1,3,5,7,9,11,13,15,17,19,21,31])\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(metrics['K'], metrics['Acc'], '-o')\n",
    "plt.xlabel('K', fontsize = 15)\n",
    "plt.ylabel('Accuracy', fontsize = 15)\n",
    "plt.title('KNN Table IX', fontsize = 15)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Acc</th>\n",
       "      <th>Sens (micro)</th>\n",
       "      <th>Sens (macro)</th>\n",
       "      <th>Sens (weighted)</th>\n",
       "      <th>Prec (micro)</th>\n",
       "      <th>Prec (macro)</th>\n",
       "      <th>Prec (weighted)</th>\n",
       "      <th>F1 (micro)</th>\n",
       "      <th>F1 (macro)</th>\n",
       "      <th>F1 (weighted)</th>\n",
       "      <th>K</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.493190</td>\n",
       "      <td>0.493190</td>\n",
       "      <td>0.494614</td>\n",
       "      <td>0.493190</td>\n",
       "      <td>0.493190</td>\n",
       "      <td>0.495333</td>\n",
       "      <td>0.489872</td>\n",
       "      <td>0.493190</td>\n",
       "      <td>0.487234</td>\n",
       "      <td>0.484345</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.513110</td>\n",
       "      <td>0.513110</td>\n",
       "      <td>0.511292</td>\n",
       "      <td>0.513110</td>\n",
       "      <td>0.513110</td>\n",
       "      <td>0.508312</td>\n",
       "      <td>0.504360</td>\n",
       "      <td>0.513110</td>\n",
       "      <td>0.499727</td>\n",
       "      <td>0.498783</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.524631</td>\n",
       "      <td>0.524631</td>\n",
       "      <td>0.525124</td>\n",
       "      <td>0.524631</td>\n",
       "      <td>0.524631</td>\n",
       "      <td>0.524016</td>\n",
       "      <td>0.519406</td>\n",
       "      <td>0.524631</td>\n",
       "      <td>0.517327</td>\n",
       "      <td>0.514826</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.510443</td>\n",
       "      <td>0.510443</td>\n",
       "      <td>0.508458</td>\n",
       "      <td>0.510443</td>\n",
       "      <td>0.510443</td>\n",
       "      <td>0.507167</td>\n",
       "      <td>0.503982</td>\n",
       "      <td>0.510443</td>\n",
       "      <td>0.497790</td>\n",
       "      <td>0.497473</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.492281</td>\n",
       "      <td>0.492281</td>\n",
       "      <td>0.487717</td>\n",
       "      <td>0.492281</td>\n",
       "      <td>0.492281</td>\n",
       "      <td>0.489264</td>\n",
       "      <td>0.484533</td>\n",
       "      <td>0.492281</td>\n",
       "      <td>0.477966</td>\n",
       "      <td>0.478064</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.478490</td>\n",
       "      <td>0.478490</td>\n",
       "      <td>0.477058</td>\n",
       "      <td>0.478490</td>\n",
       "      <td>0.478490</td>\n",
       "      <td>0.474886</td>\n",
       "      <td>0.469739</td>\n",
       "      <td>0.478490</td>\n",
       "      <td>0.466849</td>\n",
       "      <td>0.465341</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.475823</td>\n",
       "      <td>0.475823</td>\n",
       "      <td>0.471618</td>\n",
       "      <td>0.475823</td>\n",
       "      <td>0.475823</td>\n",
       "      <td>0.473368</td>\n",
       "      <td>0.466211</td>\n",
       "      <td>0.475823</td>\n",
       "      <td>0.463188</td>\n",
       "      <td>0.462198</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.468104</td>\n",
       "      <td>0.468104</td>\n",
       "      <td>0.467867</td>\n",
       "      <td>0.468104</td>\n",
       "      <td>0.468104</td>\n",
       "      <td>0.467964</td>\n",
       "      <td>0.460352</td>\n",
       "      <td>0.468104</td>\n",
       "      <td>0.461921</td>\n",
       "      <td>0.458324</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.460386</td>\n",
       "      <td>0.460386</td>\n",
       "      <td>0.458182</td>\n",
       "      <td>0.460386</td>\n",
       "      <td>0.460386</td>\n",
       "      <td>0.460451</td>\n",
       "      <td>0.453141</td>\n",
       "      <td>0.460386</td>\n",
       "      <td>0.452468</td>\n",
       "      <td>0.450080</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.462940</td>\n",
       "      <td>0.462940</td>\n",
       "      <td>0.460100</td>\n",
       "      <td>0.462940</td>\n",
       "      <td>0.462940</td>\n",
       "      <td>0.465113</td>\n",
       "      <td>0.456989</td>\n",
       "      <td>0.462940</td>\n",
       "      <td>0.456178</td>\n",
       "      <td>0.453645</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.462089</td>\n",
       "      <td>0.462089</td>\n",
       "      <td>0.455735</td>\n",
       "      <td>0.462089</td>\n",
       "      <td>0.462089</td>\n",
       "      <td>0.461621</td>\n",
       "      <td>0.455103</td>\n",
       "      <td>0.462089</td>\n",
       "      <td>0.451032</td>\n",
       "      <td>0.450842</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.455448</td>\n",
       "      <td>0.455448</td>\n",
       "      <td>0.442110</td>\n",
       "      <td>0.455448</td>\n",
       "      <td>0.455448</td>\n",
       "      <td>0.458940</td>\n",
       "      <td>0.453359</td>\n",
       "      <td>0.455448</td>\n",
       "      <td>0.439253</td>\n",
       "      <td>0.443113</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Acc  Sens (micro)  Sens (macro)  Sens (weighted)  Prec (micro)  \\\n",
       "0   0.493190      0.493190      0.494614         0.493190      0.493190   \n",
       "1   0.513110      0.513110      0.511292         0.513110      0.513110   \n",
       "2   0.524631      0.524631      0.525124         0.524631      0.524631   \n",
       "3   0.510443      0.510443      0.508458         0.510443      0.510443   \n",
       "4   0.492281      0.492281      0.487717         0.492281      0.492281   \n",
       "5   0.478490      0.478490      0.477058         0.478490      0.478490   \n",
       "6   0.475823      0.475823      0.471618         0.475823      0.475823   \n",
       "7   0.468104      0.468104      0.467867         0.468104      0.468104   \n",
       "8   0.460386      0.460386      0.458182         0.460386      0.460386   \n",
       "9   0.462940      0.462940      0.460100         0.462940      0.462940   \n",
       "10  0.462089      0.462089      0.455735         0.462089      0.462089   \n",
       "11  0.455448      0.455448      0.442110         0.455448      0.455448   \n",
       "\n",
       "    Prec (macro)  Prec (weighted)  F1 (micro)  F1 (macro)  F1 (weighted)   K  \n",
       "0       0.495333         0.489872    0.493190    0.487234       0.484345   1  \n",
       "1       0.508312         0.504360    0.513110    0.499727       0.498783   3  \n",
       "2       0.524016         0.519406    0.524631    0.517327       0.514826   5  \n",
       "3       0.507167         0.503982    0.510443    0.497790       0.497473   7  \n",
       "4       0.489264         0.484533    0.492281    0.477966       0.478064   9  \n",
       "5       0.474886         0.469739    0.478490    0.466849       0.465341  11  \n",
       "6       0.473368         0.466211    0.475823    0.463188       0.462198  13  \n",
       "7       0.467964         0.460352    0.468104    0.461921       0.458324  15  \n",
       "8       0.460451         0.453141    0.460386    0.452468       0.450080  17  \n",
       "9       0.465113         0.456989    0.462940    0.456178       0.453645  19  \n",
       "10      0.461621         0.455103    0.462089    0.451032       0.450842  21  \n",
       "11      0.458940         0.453359    0.455448    0.439253       0.443113  31  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu May  6 10:41:04 2021\n",
      "Thu May  6 10:53:49 2021\n",
      "Model: {'n_estimators': 680, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_depth': 14}\n",
      "Accuracy:             0.5485811577752554\n",
      "\n",
      "Micro Recall:         0.5485811577752554\n",
      "Macro Recall:         0.5451273416416709\n",
      "Weighted Recall:      0.5485811577752554\n",
      "\n",
      "Micro Precision:      0.5485811577752554\n",
      "Macro Precision:      0.5579716936603097\n",
      "Weighted Precision:   0.548133450787278\n",
      "\n",
      "Micro F1:             0.5485811577752554\n",
      "Macro F1:             0.5431980499649429\n",
      "Weighted F1:          0.5404587464268362\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import ParameterSampler\n",
    "\n",
    "hyper_params_tune = {'max_depth' : [i for i in range(10,20,2)],\n",
    "                     'n_estimators': [int(x) for x in np.linspace(start = 200, stop = 1000, num = 11)],\n",
    "                     'min_samples_split': [2, 5, 10],\n",
    "                     'min_samples_leaf': [1, 2, 4]}\n",
    "\n",
    "params_comb = list(ParameterSampler(hyper_params_tune, n_iter = 100, random_state = 52))\n",
    "\n",
    "best_acc = 0\n",
    "\n",
    "best_sens_micro = 0\n",
    "best_sens_macro = 0\n",
    "best_sens_weight = 0\n",
    "\n",
    "best_precs_micro = 0\n",
    "best_precs_macro = 0\n",
    "best_precs_weight = 0\n",
    "\n",
    "best_f1s_micro = 0\n",
    "best_f1s_macro = 0\n",
    "best_f1s_weight = 0\n",
    "\n",
    "\n",
    "best_p = dict()\n",
    "print(ctime())\n",
    "for i in range(0, len(params_comb)):\n",
    "    \n",
    "    rfc = RandomForestClassifier(n_jobs = -1)\n",
    "\n",
    "    for k,v in params_comb[i].items():\n",
    "        setattr(rfc, k, v)\n",
    "        \n",
    "    rfc.fit(X_train, y_train)\n",
    "    y_pred = rfc.predict(X_test)\n",
    "    \n",
    "    \n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    \n",
    "    sens_micro = recall_score(y_test, y_pred, average = 'micro')\n",
    "    sens_macro = recall_score(y_test, y_pred, average = 'macro')\n",
    "    sens_weight = recall_score(y_test, y_pred, average = 'weighted')\n",
    "    \n",
    "    precs_micro = precision_score(y_test, y_pred, average = 'micro')\n",
    "    precs_macro = precision_score(y_test, y_pred, average = 'macro')\n",
    "    precs_weight = precision_score(y_test, y_pred, average = 'weighted')\n",
    "    \n",
    "    f1s_micro = f1_score(y_test, y_pred, average = 'micro')\n",
    "    f1s_macro = f1_score(y_test, y_pred, average = 'macro')\n",
    "    f1s_weight = f1_score(y_test, y_pred, average = 'weighted')\n",
    "    \n",
    "    if acc > best_acc:\n",
    "        best_p = params_comb[i]\n",
    "        best_acc = acc\n",
    "\n",
    "        best_sens_micro = sens_micro\n",
    "        best_sens_macro = sens_macro\n",
    "        best_sens_weight = sens_weight\n",
    "\n",
    "        best_precs_micro = precs_micro\n",
    "        best_precs_macro = precs_macro\n",
    "        best_precs_weight = precs_weight\n",
    "\n",
    "        best_f1s_micro = f1s_micro\n",
    "        best_f1s_macro = f1s_macro\n",
    "        best_f1s_weight = f1s_weight\n",
    "\n",
    "print(ctime())\n",
    "print(f'Model: {best_p}')\n",
    "\n",
    "print('Accuracy:            ', best_acc, end = '\\n\\n')\n",
    "\n",
    "print('Micro Recall:        ', best_sens_micro)\n",
    "print('Macro Recall:        ', best_sens_macro)\n",
    "print('Weighted Recall:     ', best_sens_weight, end = '\\n\\n')\n",
    "\n",
    "print('Micro Precision:     ', best_precs_micro)\n",
    "print('Macro Precision:     ', best_precs_macro)\n",
    "print('Weighted Precision:  ', best_precs_weight, end = '\\n\\n')\n",
    "\n",
    "print('Micro F1:            ', best_f1s_micro)\n",
    "print('Macro F1:            ', best_f1s_macro)\n",
    "print('Weighted F1:         ', best_f1s_weight)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple RASAR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:             0.4804199772985244\n",
      "\n",
      "Micro Recall:         0.4804199772985244\n",
      "Macro Recall:         0.47010074572146243\n",
      "Weighted Recall:      0.4804199772985244\n",
      "\n",
      "Micro Precision:      0.4804199772985244\n",
      "Macro Precision:      0.4901126105696343\n",
      "Weighted Precision:   0.4793571584472678\n",
      "\n",
      "Micro F1:             0.4804199772985244\n",
      "Macro F1:             0.45220466597394554\n",
      "Weighted F1:          0.4544318562869385\n"
     ]
    }
   ],
   "source": [
    "from helper_rasar_simple_multiclass import *\n",
    "\n",
    "df_rasar_train, df_rasar_test = unsuper_simple_rasar_multiclass(new_train, new_test, y_train, y_test)\n",
    "\n",
    "clf = LogisticRegression(n_jobs = -1)\n",
    "clf.fit(df_rasar_train, y_train)\n",
    "y_pred = clf.predict(df_rasar_test)\n",
    "\n",
    "print('Accuracy:            ', accuracy_score(y_test, y_pred), end = '\\n\\n')\n",
    "\n",
    "print('Micro Recall:        ', recall_score(y_test, y_pred, average = 'micro'))\n",
    "print('Macro Recall:        ', recall_score(y_test, y_pred, average = 'macro'))\n",
    "print('Weighted Recall:     ', recall_score(y_test, y_pred, average = 'weighted'), end = '\\n\\n')\n",
    "\n",
    "print('Micro Precision:     ', precision_score(y_test, y_pred, average = 'micro'))\n",
    "print('Macro Precision:     ', precision_score(y_test, y_pred, average = 'macro'))\n",
    "print('Weighted Precision:  ', precision_score(y_test, y_pred, average = 'weighted'), end = '\\n\\n')\n",
    "\n",
    "print('Micro F1:            ', f1_score(y_test, y_pred, average = 'micro'))\n",
    "print('Macro F1:            ', f1_score(y_test, y_pred, average = 'macro'))\n",
    "print('Weighted F1:         ', f1_score(y_test, y_pred, average = 'weighted'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:             0.5265039727582292\n",
      "\n",
      "Micro Recall:         0.5265039727582292\n",
      "Macro Recall:         0.5189741599708328\n",
      "Weighted Recall:      0.5265039727582292\n",
      "\n",
      "Micro Precision:      0.5265039727582292\n",
      "Macro Precision:      0.5280595198342459\n",
      "Weighted Precision:   0.5230642401742082\n",
      "\n",
      "Micro F1:             0.5265039727582292\n",
      "Macro F1:             0.5158172819679485\n",
      "Weighted F1:          0.5183065883979093\n"
     ]
    }
   ],
   "source": [
    "from helper_rasar_simple_multiclass import *\n",
    "\n",
    "df_rasar_train, df_rasar_test = unsuper_simple_rasar_multiclass(new_train, new_test, y_train, y_test)\n",
    "\n",
    "clf = RandomForestClassifier(n_jobs = -1)\n",
    "clf.fit(df_rasar_train, y_train)\n",
    "y_pred = clf.predict(df_rasar_test)\n",
    "\n",
    "print('Accuracy:            ', accuracy_score(y_test, y_pred), end = '\\n\\n')\n",
    "\n",
    "print('Micro Recall:        ', recall_score(y_test, y_pred, average = 'micro'))\n",
    "print('Macro Recall:        ', recall_score(y_test, y_pred, average = 'macro'))\n",
    "print('Weighted Recall:     ', recall_score(y_test, y_pred, average = 'weighted'), end = '\\n\\n')\n",
    "\n",
    "print('Micro Precision:     ', precision_score(y_test, y_pred, average = 'micro'))\n",
    "print('Macro Precision:     ', precision_score(y_test, y_pred, average = 'macro'))\n",
    "print('Weighted Precision:  ', precision_score(y_test, y_pred, average = 'weighted'), end = '\\n\\n')\n",
    "\n",
    "print('Micro F1:            ', f1_score(y_test, y_pred, average = 'micro'))\n",
    "print('Macro F1:            ', f1_score(y_test, y_pred, average = 'macro'))\n",
    "print('Weighted F1:         ', f1_score(y_test, y_pred, average = 'weighted'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Fusion RASAR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from helper_rasar_datafusion import *\n",
    "from helper_rasar_simple_multiclass import *\n",
    "\n",
    "def create_label_rasar_multiclass(path_mortality, path_datafusion):\n",
    "    \n",
    "    db = pd.read_csv(path_mortality).drop(columns = 'Unnamed: 0')\n",
    "    df = pd.read_csv(path_datafusion).drop(columns = 'Unnamed: 0')\n",
    "    \n",
    "    df['fish'] = df['class'] + ' ' + df['tax_order'] + ' ' + df['family'] + ' ' + df['genus'] + ' ' + df['species']\n",
    "    \n",
    "    db['target'] = multiclass_encoding(db['conc1_mean'].copy())\n",
    "    df['target'] = multiclass_encoding(df['conc1_mean'].copy())\n",
    "    \n",
    "    comparing = ['test_cas', 'obs_duration_mean', 'conc1_type', 'exposure_type', 'control_type', 'media_type',\n",
    "             'application_freq_unit', 'fish']\n",
    "\n",
    "    grouped_datafusion = df.groupby(by=['endpoint', 'effect'])\n",
    "\n",
    "    db_datafusion_rasar_label = pd.DataFrame()\n",
    "\n",
    "    for g in grouped_datafusion.groups:\n",
    "        name = g[0] + '_' + g[1] + '_' + 'label'\n",
    "\n",
    "        group = grouped_datafusion.get_group(g).drop(columns = ['endpoint', 'effect'])\n",
    "    \n",
    "        db_datafusion_rasar_label[name] = db.apply(\n",
    "            lambda x: find_similar_exp(x, group, comparing), axis = 1).reset_index(drop = True)\n",
    "        \n",
    "    return db_datafusion_rasar_label\n",
    "\n",
    "db_label = create_label_rasar_multiclass('lc_db_processed.csv', 'datafusion_db_processed.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making df rasar db\n",
      "Accuracy:             0.5197502837684449\n",
      "\n",
      "Micro Recall:         0.5197502837684449\n",
      "Macro Recall:         0.5144560343328729\n",
      "Weighted Recall:      0.5197502837684449\n",
      "\n",
      "Micro Precision:      0.5197502837684449\n",
      "Macro Precision:      0.533522685797434\n",
      "Weighted Precision:   0.523635723961782\n",
      "\n",
      "Micro F1:             0.5197502837684449\n",
      "Macro F1:             0.5128861545793227\n",
      "Weighted F1:          0.5129618616778964\n"
     ]
    }
   ],
   "source": [
    "db_df = pd.read_csv('datafusion_db_processed.csv').drop(columns = 'Unnamed: 0')\n",
    "\n",
    "db_df = pd.concat([db_df,\n",
    "                    pd.DataFrame(pd.DataFrame(db_df['pubchem2d'].values).\\\n",
    "                                 apply(lambda x: x.str.replace('', ' ').str.strip().str.split(' '), \n",
    "                                                                            axis = 1)[0].to_list(),\n",
    "                       columns = ['pub'+ str(i) for i in range(1,882)])],\n",
    "                   axis = 1)\n",
    "\n",
    "new_db_df = db_df.copy()\n",
    "new_db_df.loc[:, numerical] = minmax.transform(db_df[numerical])\n",
    "\n",
    "for ef in new_db_df.effect.unique():\n",
    "    conc = new_db_df.loc[new_db_df.effect == ef, 'conc1_mean'].copy()\n",
    "    new_db_df.loc[new_db_df.effect == ef, 'target'] = multiclass_encoding(conc.values,\n",
    "                                                                          conc.quantile([.2,.4,.6,.8]).values)\n",
    "\n",
    "categorical.remove('fish')\n",
    "new_db_df.drop(columns = categorical, inplace = True)\n",
    "\n",
    "# Simple RASAR \n",
    "db_simple_rasar_train, db_simple_rasar_test = unsuper_simple_rasar_multiclass(new_train, new_test, y_train, y_test)\n",
    "\n",
    "print('Making df rasar db')\n",
    "# DF RASAR\n",
    "db_datafusion_rasar_train = df_datafusion_rasar(new_db_df, new_train)\n",
    "db_datafusion_rasar_test = df_datafusion_rasar(new_db_df, new_test)\n",
    "\n",
    "# FINAL DB\n",
    "X_train_rasar = pd.concat([db_simple_rasar_train, db_datafusion_rasar_train,\n",
    "                           db_label.iloc[new_train.index].reset_index(drop = True)], axis = 1)\n",
    "X_test_rasar = pd.concat([db_simple_rasar_test, db_datafusion_rasar_test,\n",
    "                          db_label.iloc[new_test.index].reset_index(drop = True)], axis = 1)\n",
    "\n",
    "\n",
    "clf = RandomForestClassifier(n_jobs = -1)\n",
    "clf.fit(X_train_rasar, y_train)\n",
    "y_pred = clf.predict(X_test_rasar)\n",
    "\n",
    "print('Accuracy:            ', accuracy_score(y_test, y_pred), end = '\\n\\n')\n",
    "\n",
    "print('Micro Recall:        ', recall_score(y_test, y_pred, average = 'micro'))\n",
    "print('Macro Recall:        ', recall_score(y_test, y_pred, average = 'macro'))\n",
    "print('Weighted Recall:     ', recall_score(y_test, y_pred, average = 'weighted'), end = '\\n\\n')\n",
    "\n",
    "print('Micro Precision:     ', precision_score(y_test, y_pred, average = 'micro'))\n",
    "print('Macro Precision:     ', precision_score(y_test, y_pred, average = 'macro'))\n",
    "print('Weighted Precision:  ', precision_score(y_test, y_pred, average = 'weighted'), end = '\\n\\n')\n",
    "\n",
    "print('Micro F1:            ', f1_score(y_test, y_pred, average = 'micro'))\n",
    "print('Macro F1:            ', f1_score(y_test, y_pred, average = 'macro'))\n",
    "print('Weighted F1:         ', f1_score(y_test, y_pred, average = 'weighted'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
