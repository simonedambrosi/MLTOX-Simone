{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tabella 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue Feb 23 12:10:17 2021\n",
      "Tue Feb 23 12:25:07 2021\n",
      "Tue Feb 23 12:35:00 2021\n",
      "Tue Feb 23 12:44:44 2021\n",
      "Tue Feb 23 12:54:40 2021\n",
      "Tue Feb 23 13:04:43 2021\n",
      "Tue Feb 23 13:14:34 2021\n",
      "Accuracy:    0.9205585310389302 se: 0.0011510478903421582\n",
      "Sensitivity: 0.8779131947364638 se: 0.0028392185365880827\n",
      "Specificity: 0.9471088518614348 se: 0.0009868549679797767\n",
      "F1 score:    0.8943372987306587 se: 0.0012875171042234885\n"
     ]
    }
   ],
   "source": [
    "from helper_rasar_datafusion import *\n",
    "\n",
    "db_mortality, db_datafusion = load_data_rasar_datafusion('lc_db_processed.csv', 'datafusion_db_processed.csv')\n",
    "print(ctime())\n",
    "db_label = create_label_rasar('lc_db_processed.csv', 'datafusion_db_processed.csv')\n",
    "cv_datafusion_rasar(db_mortality, db_datafusion, db_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tabella 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from helper_rasar_datafusion import *\n",
    "\n",
    "db = pd.read_csv('lc_db_processed.csv').drop(columns = 'Unnamed: 0')\n",
    "db_df = pd.read_csv('datafusion_db_processed.csv').drop(columns = 'Unnamed: 0')\n",
    "\n",
    "db = pd.concat([db,\n",
    "                pd.DataFrame(pd.DataFrame(db['pubchem2d'].values).\\\n",
    "                             apply(lambda x: x.str.replace('', ' ').str.strip().str.split(' '), \n",
    "                                                                        axis = 1)[0].to_list(),\n",
    "                   columns = ['pub'+ str(i) for i in range(1,882)])],\n",
    "               axis = 1)\n",
    "\n",
    "db_df = pd.concat([db_df,\n",
    "                    pd.DataFrame(pd.DataFrame(db_df['pubchem2d'].values).\\\n",
    "                                 apply(lambda x: x.str.replace('', ' ').str.strip().str.split(' '), \n",
    "                                                                            axis = 1)[0].to_list(),\n",
    "                       columns = ['pub'+ str(i) for i in range(1,882)])],\n",
    "                   axis = 1)\n",
    "\n",
    "numerical = ['atom_number', 'bonds_number','Mol', 'MorganDensity', 'LogP',\n",
    "            'alone_atom_number', 'doubleBond', 'tripleBond', 'ring_number', 'oh_count', 'MeltingPoint', 'WaterSolubility']\n",
    "\n",
    "for nc in numerical:\n",
    "        minmax = MinMaxScaler()\n",
    "        minmax.fit(db[[nc]])\n",
    "        db[[nc]] = minmax.transform(db[[nc]])\n",
    "\n",
    "for nc in numerical:\n",
    "    minmax = MinMaxScaler()\n",
    "    minmax.fit(db_df[[nc]])\n",
    "    db_df[[nc]] = minmax.transform(db_df[[nc]])\n",
    "\n",
    "\n",
    "categorical = ['obs_duration_mean',\n",
    "               'conc1_type', 'exposure_type', 'control_type', 'media_type',\n",
    "               'application_freq_unit', 'species', 'class', 'tax_order', 'family', 'genus']\n",
    "\n",
    "db.drop(columns = categorical, inplace = True)\n",
    "db_df.drop(columns = categorical, inplace = True)\n",
    "\n",
    "db = db.groupby('test_cas').agg('median').reset_index()\n",
    "db_df = db_df.groupby(['test_cas', 'endpoint', 'effect']).agg('median').reset_index()\n",
    "\n",
    "db['target'] = np.where(db['conc1_mean']> 1, 0,1)\n",
    "db_df['target'] = np.where(db_df['conc1_mean']> 1, 0,1)\n",
    "\n",
    "db.drop(columns = ['conc1_mean'], inplace = True)\n",
    "db_df.drop(columns = ['conc1_mean'], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_label_rasar_tab1(db, df):\n",
    "    \n",
    "    comparing = ['test_cas']\n",
    "\n",
    "    grouped_datafusion = df.groupby(by=['endpoint', 'effect'])\n",
    "\n",
    "    db_datafusion_rasar_label = pd.DataFrame()\n",
    "\n",
    "    for g in grouped_datafusion.groups:\n",
    "        name = g[0] + '_' + g[1] + '_' + 'label'\n",
    "\n",
    "        group = grouped_datafusion.get_group(g).drop(columns = ['endpoint', 'effect'])\n",
    "    \n",
    "        db_datafusion_rasar_label[name] = db.apply(\n",
    "            lambda x: find_similar_exp(x, group, comparing), axis = 1).reset_index(drop = True)\n",
    "        \n",
    "    return db_datafusion_rasar_label    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue Feb 23 18:48:03 2021\n",
      "Tue Feb 23 18:48:53 2021\n",
      "Tue Feb 23 18:49:01 2021\n",
      "Tue Feb 23 18:49:09 2021\n",
      "Tue Feb 23 18:49:17 2021\n",
      "Tue Feb 23 18:49:24 2021\n",
      "Tue Feb 23 18:49:32 2021\n",
      "Accuracy:    0.8299223441706356 se: 0.001961120478081154\n",
      "Sensitivity: 0.3632890563926483 se: 0.020474687512452773\n",
      "Specificity: 0.9542000271905302 se: 0.007621162309837269\n",
      "F1 score:    0.47048136205221597 se: 0.015984854516224244\n"
     ]
    }
   ],
   "source": [
    "print(ctime())\n",
    "db_label = create_label_rasar_tab1(db, db_df)\n",
    "db.drop(columns = 'test_cas', inplace = True)\n",
    "db_df.drop(columns = 'test_cas', inplace = True)\n",
    "\n",
    "cv_datafusion_rasar(db, db_df, db_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tabella 2 -- Fathead Minnow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from helper_rasar_datafusion import *\n",
    "\n",
    "db = pd.read_csv('lc_db_processed.csv').drop(columns = 'Unnamed: 0')\n",
    "db_df = pd.read_csv('datafusion_db_processed.csv').drop(columns = 'Unnamed: 0')\n",
    "\n",
    "db = pd.concat([db,\n",
    "                pd.DataFrame(pd.DataFrame(db['pubchem2d'].values).\\\n",
    "                             apply(lambda x: x.str.replace('', ' ').str.strip().str.split(' '), \n",
    "                                                                        axis = 1)[0].to_list(),\n",
    "                   columns = ['pub'+ str(i) for i in range(1,882)])],\n",
    "               axis = 1)\n",
    "\n",
    "db_df = pd.concat([db_df,\n",
    "                    pd.DataFrame(pd.DataFrame(db_df['pubchem2d'].values).\\\n",
    "                                 apply(lambda x: x.str.replace('', ' ').str.strip().str.split(' '), \n",
    "                                                                            axis = 1)[0].to_list(),\n",
    "                       columns = ['pub'+ str(i) for i in range(1,882)])],\n",
    "                   axis = 1)\n",
    "\n",
    "numerical = ['atom_number', 'bonds_number','Mol', 'MorganDensity', 'LogP',\n",
    "            'alone_atom_number', 'doubleBond', 'tripleBond', 'ring_number', 'oh_count', 'MeltingPoint', 'WaterSolubility']\n",
    "\n",
    "for nc in numerical:\n",
    "        minmax = MinMaxScaler()\n",
    "        minmax.fit(db[[nc]])\n",
    "        db[[nc]] = minmax.transform(db[[nc]])\n",
    "\n",
    "for nc in numerical:\n",
    "    minmax = MinMaxScaler()\n",
    "    minmax.fit(db_df[[nc]])\n",
    "    db_df[[nc]] = minmax.transform(db_df[[nc]])\n",
    "\n",
    "\n",
    "species = pd.read_csv('C:/Users/Simone/Desktop/Utilità tesi magistrale/data/species.txt', sep = '\\|', engine = 'python')\n",
    "\n",
    "fm = species[species['common_name'] == 'Fathead Minnow'][\n",
    "    ['class', 'tax_order', 'family', 'genus', 'species']].values.ravel()\n",
    "\n",
    "X_train = db.loc[(db[\n",
    "    ['class', 'tax_order', 'family', 'genus', 'species']] == fm).all(axis =1)].copy().reset_index(drop=True)\n",
    "y_train = np.where(X_train['conc1_mean'] > 1, 0,1)\n",
    "\n",
    "X_test = db.loc[~(db[\n",
    "    ['class', 'tax_order', 'family', 'genus', 'species']] == fm).all(axis = 1)].copy().reset_index(drop=True)\n",
    "y_test = np.where(X_test['conc1_mean'] > 1, 0,1)\n",
    "\n",
    "db_df['target'] = np.where(db_df['conc1_mean']> 1, 0,1)\n",
    "\n",
    "categorical = ['fish', 'smiles', 'pubchem2d', 'conc1_mean', 'obs_duration_mean',\n",
    "               'conc1_type', 'exposure_type', 'control_type', 'media_type',\n",
    "               'application_freq_unit', 'species', 'class', 'tax_order', 'family', 'genus']\n",
    "\n",
    "X_train.drop(columns = categorical, inplace = True)\n",
    "X_test.drop(columns = categorical, inplace = True)\n",
    "categorical.remove('fish')\n",
    "db_df.drop(columns = categorical, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label_train Wed Feb 24 11:36:08 2021\n",
      "label_test Wed Feb 24 11:37:14 2021\n",
      "db_train e test Wed Feb 24 11:43:56 2021\n",
      "fine Wed Feb 24 11:47:19 2021\n"
     ]
    }
   ],
   "source": [
    "def create_label_rasar_tab1(db, df):\n",
    "    \n",
    "    comparing = ['test_cas']\n",
    "\n",
    "    grouped_datafusion = df.groupby(by=['endpoint', 'effect'])\n",
    "\n",
    "    db_datafusion_rasar_label = pd.DataFrame()\n",
    "\n",
    "    for g in grouped_datafusion.groups:\n",
    "        name = g[0] + '_' + g[1] + '_' + 'label'\n",
    "\n",
    "        group = grouped_datafusion.get_group(g).drop(columns = ['endpoint', 'effect'])\n",
    "    \n",
    "        db_datafusion_rasar_label[name] = db.apply(\n",
    "            lambda x: find_similar_exp(x, group, comparing), axis = 1).reset_index(drop = True)\n",
    "        \n",
    "    return db_datafusion_rasar_label  \n",
    "\n",
    "def rasar_train_test(db_train, db_test, y_train, y_test, db_datafusion, db_label_train, db_label_test):\n",
    "    \n",
    "    db_simple_rasar_train = df_train_simple_rasar(db_train, y_train)\n",
    "    \n",
    "    db_simple_rasar_test = df_test_simple_rasar(db_train, db_test, y_train, y_test)\n",
    "    \n",
    "    db_datafusion_rasar_train = df_datafusion_rasar(db_datafusion, db_train)\n",
    "    \n",
    "    db_datafusion_rasar_test = df_datafusion_rasar(db_datafusion, db_test)\n",
    "    \n",
    "    X_train_rasar = pd.concat([db_simple_rasar_train[['dist_neigh0', 'dist_neigh1']], db_datafusion_rasar_train,\n",
    "                               db_label_train], axis = 1)\n",
    "    X_test_rasar = pd.concat([db_simple_rasar_test[['dist_neigh0', 'dist_neigh1']], db_datafusion_rasar_test,\n",
    "                             db_label_test], axis = 1)\n",
    "    \n",
    "    return X_train_rasar, X_test_rasar\n",
    "\n",
    "print('label_train', ctime())\n",
    "db_label_train = create_label_rasar_tab1(X_train, db_df)\n",
    "print('label_test', ctime())\n",
    "db_label_test = create_label_rasar_tab1(X_test, db_df)\n",
    "\n",
    "X_train.drop(columns = 'test_cas', inplace = True)\n",
    "X_test.drop(columns = 'test_cas', inplace = True)\n",
    "db_df.drop(columns = 'test_cas', inplace = True)\n",
    "print('db_train e test', ctime())\n",
    "X_train_rasar, X_test_rasar = rasar_train_test(X_train, X_test, y_train, y_test, db_df, db_label_train, db_label_test)\n",
    "print('fine', ctime())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed Feb 24 11:55:31 2021\n",
      "Accuracy:  0.8190542259220719 \n",
      " Sensitivity: 0.6608203677510608 \n",
      " Specificity: 0.9284317559640204 \n",
      " F1 score: 0.7490780824114157\n"
     ]
    }
   ],
   "source": [
    "clf = RandomForestClassifier(n_jobs = -1)\n",
    "clf.fit(X_train_rasar, y_train)\n",
    "y_pred = clf.predict(X_test_rasar)\n",
    "\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "\n",
    "print(ctime())\n",
    "print(\"Accuracy: \", accuracy_score(y_test, y_pred),\n",
    "\"\\n Sensitivity:\", recall_score(y_test, y_pred),\n",
    "\"\\n Specificity:\", tn/(tn+fp),\n",
    "\"\\n F1 score:\", f1_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rainbow Trout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label_train Wed Feb 24 11:59:27 2021\n",
      "label_test Wed Feb 24 12:00:25 2021\n",
      "db_train e test Wed Feb 24 12:08:12 2021\n",
      "fine Wed Feb 24 12:11:22 2021\n",
      "Wed Feb 24 12:11:23 2021\n",
      "Accuracy:  0.8319523269012485 \n",
      " Sensitivity: 0.8567348165965123 \n",
      " Specificity: 0.8169219547775346 \n",
      " F1 score: 0.7937878682359495\n"
     ]
    }
   ],
   "source": [
    "from helper_rasar_datafusion import *\n",
    "\n",
    "db = pd.read_csv('lc_db_processed.csv').drop(columns = 'Unnamed: 0')\n",
    "db_df = pd.read_csv('datafusion_db_processed.csv').drop(columns = 'Unnamed: 0')\n",
    "\n",
    "db = pd.concat([db,\n",
    "                pd.DataFrame(pd.DataFrame(db['pubchem2d'].values).\\\n",
    "                             apply(lambda x: x.str.replace('', ' ').str.strip().str.split(' '), \n",
    "                                                                        axis = 1)[0].to_list(),\n",
    "                   columns = ['pub'+ str(i) for i in range(1,882)])],\n",
    "               axis = 1)\n",
    "\n",
    "db_df = pd.concat([db_df,\n",
    "                    pd.DataFrame(pd.DataFrame(db_df['pubchem2d'].values).\\\n",
    "                                 apply(lambda x: x.str.replace('', ' ').str.strip().str.split(' '), \n",
    "                                                                            axis = 1)[0].to_list(),\n",
    "                       columns = ['pub'+ str(i) for i in range(1,882)])],\n",
    "                   axis = 1)\n",
    "\n",
    "numerical = ['atom_number', 'bonds_number','Mol', 'MorganDensity', 'LogP',\n",
    "            'alone_atom_number', 'doubleBond', 'tripleBond', 'ring_number', 'oh_count', 'MeltingPoint', 'WaterSolubility']\n",
    "\n",
    "for nc in numerical:\n",
    "        minmax = MinMaxScaler()\n",
    "        minmax.fit(db[[nc]])\n",
    "        db[[nc]] = minmax.transform(db[[nc]])\n",
    "\n",
    "for nc in numerical:\n",
    "    minmax = MinMaxScaler()\n",
    "    minmax.fit(db_df[[nc]])\n",
    "    db_df[[nc]] = minmax.transform(db_df[[nc]])\n",
    "\n",
    "\n",
    "species = pd.read_csv('C:/Users/Simone/Desktop/Utilità tesi magistrale/data/species.txt', sep = '\\|', engine = 'python')\n",
    "\n",
    "fm = species[species['common_name'] == 'Rainbow Trout'][\n",
    "    ['class', 'tax_order', 'family', 'genus', 'species']].values.ravel()\n",
    "\n",
    "X_train = db.loc[(db[\n",
    "    ['class', 'tax_order', 'family', 'genus', 'species']] == fm).all(axis =1)].copy().reset_index(drop=True)\n",
    "y_train = np.where(X_train['conc1_mean'] > 1, 0,1)\n",
    "\n",
    "X_test = db.loc[~(db[\n",
    "    ['class', 'tax_order', 'family', 'genus', 'species']] == fm).all(axis = 1)].copy().reset_index(drop=True)\n",
    "y_test = np.where(X_test['conc1_mean'] > 1, 0,1)\n",
    "\n",
    "db_df['target'] = np.where(db_df['conc1_mean']> 1, 0,1)\n",
    "\n",
    "categorical = ['fish', 'smiles', 'pubchem2d', 'conc1_mean', 'obs_duration_mean',\n",
    "               'conc1_type', 'exposure_type', 'control_type', 'media_type',\n",
    "               'application_freq_unit', 'species', 'class', 'tax_order', 'family', 'genus']\n",
    "\n",
    "X_train.drop(columns = categorical, inplace = True)\n",
    "X_test.drop(columns = categorical, inplace = True)\n",
    "categorical.remove('fish')\n",
    "db_df.drop(columns = categorical, inplace = True)\n",
    "\n",
    "def create_label_rasar_tab1(db, df):\n",
    "    \n",
    "    comparing = ['test_cas']\n",
    "\n",
    "    grouped_datafusion = df.groupby(by=['endpoint', 'effect'])\n",
    "\n",
    "    db_datafusion_rasar_label = pd.DataFrame()\n",
    "\n",
    "    for g in grouped_datafusion.groups:\n",
    "        name = g[0] + '_' + g[1] + '_' + 'label'\n",
    "\n",
    "        group = grouped_datafusion.get_group(g).drop(columns = ['endpoint', 'effect'])\n",
    "    \n",
    "        db_datafusion_rasar_label[name] = db.apply(\n",
    "            lambda x: find_similar_exp(x, group, comparing), axis = 1).reset_index(drop = True)\n",
    "        \n",
    "    return db_datafusion_rasar_label  \n",
    "\n",
    "def rasar_train_test(db_train, db_test, y_train, y_test, db_datafusion, db_label_train, db_label_test):\n",
    "    \n",
    "    db_simple_rasar_train = df_train_simple_rasar(db_train, y_train)\n",
    "    \n",
    "    db_simple_rasar_test = df_test_simple_rasar(db_train, db_test, y_train, y_test)\n",
    "    \n",
    "    db_datafusion_rasar_train = df_datafusion_rasar(db_datafusion, db_train)\n",
    "    \n",
    "    db_datafusion_rasar_test = df_datafusion_rasar(db_datafusion, db_test)\n",
    "    \n",
    "    X_train_rasar = pd.concat([db_simple_rasar_train[['dist_neigh0', 'dist_neigh1']], db_datafusion_rasar_train,\n",
    "                               db_label_train], axis = 1)\n",
    "    X_test_rasar = pd.concat([db_simple_rasar_test[['dist_neigh0', 'dist_neigh1']], db_datafusion_rasar_test,\n",
    "                             db_label_test], axis = 1)\n",
    "    \n",
    "    return X_train_rasar, X_test_rasar\n",
    "\n",
    "print('label_train', ctime())\n",
    "db_label_train = create_label_rasar_tab1(X_train, db_df)\n",
    "print('label_test', ctime())\n",
    "db_label_test = create_label_rasar_tab1(X_test, db_df)\n",
    "\n",
    "X_train.drop(columns = 'test_cas', inplace = True)\n",
    "X_test.drop(columns = 'test_cas', inplace = True)\n",
    "db_df.drop(columns = 'test_cas', inplace = True)\n",
    "print('db_train e test', ctime())\n",
    "X_train_rasar, X_test_rasar = rasar_train_test(X_train, X_test, y_train, y_test, db_df, db_label_train, db_label_test)\n",
    "print('fine', ctime())\n",
    "\n",
    "\n",
    "clf = RandomForestClassifier(n_jobs = -1)\n",
    "clf.fit(X_train_rasar, y_train)\n",
    "y_pred = clf.predict(X_test_rasar)\n",
    "\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "\n",
    "print(ctime())\n",
    "print(\"Accuracy: \", accuracy_score(y_test, y_pred),\n",
    "\"\\n Sensitivity:\", recall_score(y_test, y_pred),\n",
    "\"\\n Specificity:\", tn/(tn+fp),\n",
    "\"\\n F1 score:\", f1_score(y_test, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
