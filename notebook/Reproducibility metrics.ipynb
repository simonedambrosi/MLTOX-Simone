{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start! Wed Feb  3 15:29:08 2021\n",
      "Loading raw data\n",
      "tests table loaded!\n",
      "species table loaded!\n",
      "results table loaded!\n",
      "Tests table dimensions:  (681605, 122)\n",
      "Species table dimensions:  (27125, 15)\n",
      "Results table dimensions:  (1006972, 137)\n",
      "Prefiltering Step... Wed Feb  3 15:31:15 2021\n",
      "Dimensions after prefiltering step:  (64341, 272)\n",
      "Selection and Imputation Step... Wed Feb  3 15:31:28 2021\n",
      "Features:\n",
      "obs_duration_mean, obs_duration_unit, endpoint, effect, measurement, conc1_type, conc1_mean, conc1_unit, test_cas, test_location, exposure_type, control_type, media_type, application_freq_unit, class, tax_order, family, genus, species, \n",
      "Dimension after imputation step: (50160, 16)\n"
     ]
    }
   ],
   "source": [
    "from helper_preprocessing import *\n",
    "\n",
    "path_tests = 'C:/Users/Simone/Desktop/Utilità tesi magistrale/data/tests.txt'\n",
    "path_species = 'C:/Users/Simone/Desktop/Utilità tesi magistrale/data/species.txt'\n",
    "path_results = 'C:/Users/Simone/Desktop/Utilità tesi magistrale/data/results.txt'\n",
    "\n",
    "\n",
    "tests, species, results = load_raw_data(path_tests, path_results, path_species)\n",
    "\n",
    "prefiltered_data = prefilter(species, tests, results)\n",
    "\n",
    "del tests, species, results\n",
    "\n",
    "db = select_impute_features(prefiltered_data)\n",
    "db.to_csv('no_repeated_experiments.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9579867656199943\n",
      "0.9387028706463307\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from general_helper import multiclass_encoding\n",
    "\n",
    "def rep_exp_sensitivity(lout_exp):\n",
    "    lst = [(1,i) for i in lout_exp]\n",
    "    return (lst.count((1,1)) -1) / (len(lst) - 1)\n",
    "   \n",
    "def rep_exp_specificity(lout_exp):\n",
    "    lst = [(0,i) for i in lout_exp]\n",
    "    return (lst.count((0,0)) -1) / (len(lst) - 1)\n",
    "\n",
    "imp_db = pd.read_csv('no_repeated_experiments.csv').drop(columns = 'Unnamed: 0')\n",
    "\n",
    "imp_db['fish'] = imp_db['class'] + ' ' + imp_db['tax_order'] + ' ' + imp_db['family'] + ' ' +\\\n",
    "                        imp_db['genus'] + ' ' + imp_db['species']\n",
    "\n",
    "imp_db['enc_conc'] = np.where(imp_db['conc1_mean'] > 1, 0, 1)\n",
    "\n",
    "gdb = imp_db.groupby(['test_cas', 'obs_duration_mean', 'conc1_type', 'fish', 'exposure_type',\n",
    "                     'control_type', 'media_type', 'application_freq_unit'])\n",
    "gr = gdb.groups\n",
    "\n",
    "specs = []\n",
    "sens = []\n",
    "for group in gr:\n",
    "    lst = gdb.get_group(group).enc_conc.values.tolist()\n",
    "    if len(lst) == 1:\n",
    "        continue\n",
    "    sen = rep_exp_sensitivity(lst)\n",
    "    spec = rep_exp_specificity(lst)\n",
    "\n",
    "    if sen > 0:\n",
    "        sens.append(sen)\n",
    "    if spec > 0:\n",
    "        specs.append(spec)\n",
    "       \n",
    "    \n",
    "print(np.mean(specs))\n",
    "print(np.mean(sens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sensitivity_avg:0.8596730691306851\n",
      "specificity_avg:0.7820887477946522\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "db_score_tot = pd.read_csv('no_repeated_experiments.csv').drop(['Unnamed: 0'],axis=1)\n",
    "\n",
    "db_score_tot['fish'] = db_score_tot['class'] + ' ' + db_score_tot['tax_order'] + ' ' + db_score_tot['family'] + ' ' +\\\n",
    "                        db_score_tot['genus'] + ' ' + db_score_tot['species']\n",
    "\n",
    "db_score_tot['score'] = np.where(db_score_tot['conc1_mean'].values > 1, 1, 0)\n",
    "\n",
    "db_pair_num = pd.DataFrame(pd.pivot_table(data =db_score_tot, index=['test_cas', 'obs_duration_mean', 'conc1_type',\n",
    "                                                                     'fish', 'exposure_type', 'control_type',\n",
    "                                                                     'media_type', 'application_freq_unit'], \n",
    "                                          aggfunc='size'))\n",
    "db_pair_num.rename(columns={ db_pair_num.columns[-1]: \"count\" }, inplace = True)\n",
    "\n",
    "\n",
    "def count_pair(n):\n",
    "    return sum(range(int(n)))\n",
    "db_pair_num['count'] = db_pair_num['count'].apply(count_pair)\n",
    "\n",
    "\n",
    "# count pairs for sensitivity and specificity\n",
    "def se_sp(scores):\n",
    "    if not np.any(scores):\n",
    "        return None\n",
    "    else:\n",
    "        return np.sum([sum(scores[:i]) for i, score in enumerate(scores) if score==1])\n",
    "            \n",
    "def calculate_se_sp(db_score_tot):\n",
    "    df = db_score_tot.groupby(['test_cas', 'obs_duration_mean', 'conc1_type',\n",
    "                                 'fish', 'exposure_type', 'control_type',\n",
    "                                 'media_type', 'application_freq_unit'])['score'].apply(np.array).reset_index()\n",
    "    df['pair_se'] = df['score'].apply(se_sp)\n",
    "    \n",
    "    # switch the 0s and 1s \n",
    "    df['score'] = 1 - df['score']\n",
    "    df['pair_sp'] = df['score'].apply(se_sp)\n",
    "    \n",
    "    df.drop(columns='score', inplace=True)\n",
    "    return df\n",
    "\n",
    "db_se_sp = calculate_se_sp(db_score_tot)\n",
    "\n",
    "final_sp_se = pd.merge(db_se_sp, db_pair_num, how= 'left',on=['test_cas', 'obs_duration_mean', 'conc1_type',\n",
    "                                 'fish', 'exposure_type', 'control_type',\n",
    "                                 'media_type', 'application_freq_unit'])\n",
    "final_sp_se['SE']  = final_sp_se['pair_se'].divide(final_sp_se['count'])\n",
    "sensitivity = final_sp_se.loc[final_sp_se['SE'].between(0,1),'SE'].mean()\n",
    "\n",
    "# specificity \n",
    "final_sp_se['SP']  = final_sp_se['pair_sp'].divide(final_sp_se['count'])\n",
    "specificity = final_sp_se.loc[final_sp_se['SP'].between(0,1),'SP'].mean()\n",
    "\n",
    "print('sensitivity_avg:',sensitivity,'\\n', 'specificity_avg:', specificity,sep='')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
