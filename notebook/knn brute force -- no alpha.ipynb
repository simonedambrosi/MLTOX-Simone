{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NO PUBCHEM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "db = pd.read_csv('lc_db_processed.csv').drop(columns = ['Unnamed: 0', 'fish'])\n",
    "db['conc1_mean'] = np.where(db['conc1_mean'] > 1, 0,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utilizzo tutte le caratteristiche con MinMax solo su train set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: \t 0.7186211049224747 se: 0.0007194221373083567\n",
      "Sensitivity: 0.6298330975522243 se: 0.004245959606335624\n",
      "Specificity: 0.7735177528428461 se: 0.0018142058199968204\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, recall_score, confusion_matrix\n",
    "from scipy.stats import sem\n",
    "from sklearn.preprocessing import OneHotEncoder, MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "lst = db.select_dtypes('object').columns.tolist()\n",
    "lst.remove('smiles')\n",
    "lst.remove('pubchem2d')\n",
    "lst.remove('test_cas')\n",
    "\n",
    "encoder = OneHotEncoder(sparse = False)\n",
    "encoder.fit(db[lst])\n",
    "X = pd.concat([db.drop(columns = lst), pd.DataFrame(encoder.transform(db[lst]),\n",
    "                                                    columns = encoder.get_feature_names(lst))], axis = 1)\n",
    "\n",
    "accs = []\n",
    "sens = []\n",
    "specs = []\n",
    "\n",
    "numerical = ['atom_number', 'bonds_number','Mol', 'MorganDensity', 'LogP',\n",
    "            'alone_atom_number', 'doubleBond', 'tripleBond', 'ring_number', 'oh_count', 'MeltingPoint', 'WaterSolubility']\n",
    "\n",
    "for i in range(0,5):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X.drop(columns = ['test_cas', 'conc1_mean','smiles','pubchem2d']),\n",
    "                                                    db['conc1_mean'], test_size = 0.33)\n",
    "\n",
    "    minmax = MinMaxScaler()\n",
    "    minmax.fit(X_train[numerical])\n",
    "    new_train = X_train.copy()\n",
    "    new_train.loc[:, numerical] = minmax.transform(X_train[numerical])\n",
    "    \n",
    "    new_test = X_test.copy()\n",
    "    new_test.loc[:, numerical] = minmax.transform(X_test[numerical])\n",
    "    \n",
    "    \n",
    "    knn = KNeighborsClassifier(n_neighbors = 1)\n",
    "    knn.fit(new_train, y_train) ########################## cambiare se faccio minmax\n",
    "    y_pred = knn.predict(new_test)\n",
    "    accs.append(accuracy_score(y_test, y_pred))\n",
    "    sens.append(recall_score(y_test, y_pred))\n",
    "    \n",
    "    tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "    \n",
    "    specs.append(tn/(tn+fp))\n",
    "    \n",
    "print('Accuracy: \\t', np.mean(accs), 'se:', sem(accs))\n",
    "print('Sensitivity:', np.mean(sens), 'se:', sem(sens))\n",
    "print('Specificity:', np.mean(specs), 'se:', sem(specs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Senza MinMax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8465151287069096 se: 0.001652179301332399\n",
      "Sensitivity: 0.8048755398420662 se: 0.00263331111249059\n",
      "Specificity: 0.8723533629717203 se: 0.002573035748697218\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, recall_score, confusion_matrix\n",
    "from scipy.stats import sem\n",
    "from sklearn.preprocessing import OneHotEncoder, MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "lst = db.select_dtypes('object').columns.tolist()\n",
    "lst.remove('smiles')\n",
    "lst.remove('pubchem2d')\n",
    "lst.remove('test_cas')\n",
    "\n",
    "encoder = OneHotEncoder(sparse = False)\n",
    "encoder.fit(db[lst])\n",
    "X = pd.concat([db.drop(columns = lst), pd.DataFrame(encoder.transform(db[lst]),\n",
    "                                                    columns = encoder.get_feature_names(lst))], axis = 1)\n",
    "\n",
    "accs = []\n",
    "sens = []\n",
    "specs = []\n",
    "\n",
    "for i in range(0,5):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X.drop(columns = ['test_cas', 'conc1_mean','smiles','pubchem2d']),\n",
    "                                                    db['conc1_mean'], test_size = 0.33)\n",
    "    \n",
    "    knn = KNeighborsClassifier(n_neighbors = 1)\n",
    "    knn.fit(X_train, y_train)\n",
    "    y_pred = knn.predict(X_test)\n",
    "    accs.append(accuracy_score(y_test, y_pred))\n",
    "    sens.append(recall_score(y_test, y_pred))\n",
    "    \n",
    "    tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "    \n",
    "    specs.append(tn/(tn+fp))\n",
    "    \n",
    "print('Accuracy: \\t', np.mean(accs), 'se:', sem(accs))\n",
    "print('Sensitivity:', np.mean(sens), 'se:', sem(sens))\n",
    "print('Specificity:', np.mean(specs), 'se:', sem(specs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K = 1,3,5,7,9,21,31"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K= 1\n",
      "Accuracy: \t 0.8437452958000902 se: 0.002474906352566894\n",
      "Sensitivity: 0.7991608232058054 se: 0.002888160628217317\n",
      "Specificity: 0.8713235663004812 se: 0.003034667735990581\n",
      "K= 3\n",
      "Accuracy: \t 0.8530483215414723 se: 0.0020204161286810456\n",
      "Sensitivity: 0.7954936077048934 se: 0.002947714417339753\n",
      "Specificity: 0.888039802448958 se: 0.002703594332515464\n",
      "K= 5\n",
      "Accuracy: \t 0.8487731446635557 se: 0.001626607576003621\n",
      "Sensitivity: 0.7809563905387625 se: 0.001908825617360951\n",
      "Specificity: 0.8905722397684853 se: 0.0025376799483555505\n",
      "K= 7\n",
      "Accuracy: \t 0.8438055095589343 se: 0.0017751573708875948\n",
      "Sensitivity: 0.7660310936058166 se: 0.003059176932038515\n",
      "Specificity: 0.8918709240779028 se: 0.0016467215507962871\n",
      "K= 9\n",
      "Accuracy: \t 0.8382658437452959 se: 0.0007902697424902444\n",
      "Sensitivity: 0.7648980256053646 se: 0.0015650145751834655\n",
      "Specificity: 0.8841483175905033 se: 0.0017190440536746178\n",
      "K= 21\n",
      "Accuracy: \t 0.8154448291434593 se: 0.0007719934610843199\n",
      "Sensitivity: 0.7184053393745412 se: 0.001695682967899962\n",
      "Specificity: 0.8761576318115771 se: 0.001161250493974898\n",
      "K= 31\n",
      "Accuracy: \t 0.8042450699984947 se: 0.0018593283343844062\n",
      "Sensitivity: 0.6914207719983089 se: 0.0061005617552641455\n",
      "Specificity: 0.8740919661472976 se: 0.0011409953872527215\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, recall_score, confusion_matrix\n",
    "from scipy.stats import sem\n",
    "from sklearn.preprocessing import OneHotEncoder, MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "lst = db.select_dtypes('object').columns.tolist()\n",
    "lst.remove('smiles')\n",
    "lst.remove('pubchem2d')\n",
    "lst.remove('test_cas')\n",
    "\n",
    "encoder = OneHotEncoder(sparse = False)\n",
    "encoder.fit(db[lst])\n",
    "X = pd.concat([db.drop(columns = lst), pd.DataFrame(encoder.transform(db[lst]),\n",
    "                                                    columns = encoder.get_feature_names(lst))], axis = 1)\n",
    "for k in [1,3,5,7,9,21,31]:\n",
    "    accs = []\n",
    "    sens = []\n",
    "    specs = []\n",
    "    for i in range(0,5):\n",
    "        X_train, X_test, y_train, y_test = train_test_split(\n",
    "            X.drop(columns = ['test_cas', 'conc1_mean','smiles','pubchem2d']), db['conc1_mean'], test_size = 0.33)\n",
    "\n",
    "        knn = KNeighborsClassifier(n_neighbors = k)\n",
    "        knn.fit(X_train, y_train)\n",
    "        y_pred = knn.predict(X_test)\n",
    "        accs.append(accuracy_score(y_test, y_pred))\n",
    "        sens.append(recall_score(y_test, y_pred))\n",
    "\n",
    "        tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "\n",
    "        specs.append(tn/(tn+fp))\n",
    "    print('K=',k)\n",
    "    print('Accuracy:', np.mean(accs), 'se:', sem(accs))\n",
    "    print('Sensitivity:', np.mean(sens), 'se:', sem(sens))\n",
    "    print('Specificity:', np.mean(specs), 'se:', sem(specs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Con MinMax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K= 1\n",
      "Accuracy: 0.7187415324401626 se: 0.002063804075461544\n",
      "Sensitivity: 0.6216901863785576 se: 0.005107220834440396\n",
      "Specificity: 0.7790155420184938 se: 0.0035716763659116683\n",
      "K= 3\n",
      "Accuracy: 0.7328315520096342 se: 0.003184220622518321\n",
      "Sensitivity: 0.6076245019215643 se: 0.003943321328589471\n",
      "Specificity: 0.8100852462408576 se: 0.002670491179487638\n",
      "K= 5\n",
      "Accuracy: 0.7335240102363391 se: 0.0013074846154212632\n",
      "Sensitivity: 0.589983324067384 se: 0.004434690206336319\n",
      "Specificity: 0.8229517889748669 se: 0.0038627324484566397\n",
      "K= 7\n",
      "Accuracy: 0.7403582718651214 se: 0.001252605392907715\n",
      "Sensitivity: 0.5962162323011114 se: 0.003025056529794031\n",
      "Specificity: 0.82987722480654 se: 0.002628822430285733\n",
      "K= 9\n",
      "Accuracy: 0.7350293542074364 se: 0.002972587459077098\n",
      "Sensitivity: 0.572497006105925 se: 0.004922890231733209\n",
      "Specificity: 0.8359572593111227 se: 0.0028576338256649262\n",
      "K= 21\n",
      "Accuracy: 0.7257263284660544 se: 0.0021315372961773814\n",
      "Sensitivity: 0.5063421716726607 se: 0.0033434635000729684\n",
      "Specificity: 0.8636168603383089 se: 0.004226064418595679\n",
      "K= 31\n",
      "Accuracy: 0.7200361282553064 se: 0.0022263828680089606\n",
      "Sensitivity: 0.47194436974016823 se: 0.004768706663803323\n",
      "Specificity: 0.8768050620305387 se: 0.0033582024233391617\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, recall_score, confusion_matrix\n",
    "from scipy.stats import sem\n",
    "from sklearn.preprocessing import OneHotEncoder, MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "lst = db.select_dtypes('object').columns.tolist()\n",
    "lst.remove('smiles')\n",
    "lst.remove('pubchem2d')\n",
    "lst.remove('test_cas')\n",
    "\n",
    "numerical = ['atom_number', 'bonds_number','Mol', 'MorganDensity', 'LogP',\n",
    "            'alone_atom_number', 'doubleBond', 'tripleBond', 'ring_number', 'oh_count', 'MeltingPoint', 'WaterSolubility']\n",
    "\n",
    "encoder = OneHotEncoder(sparse = False)\n",
    "encoder.fit(db[lst])\n",
    "X = pd.concat([db.drop(columns = lst), pd.DataFrame(encoder.transform(db[lst]),\n",
    "                                                    columns = encoder.get_feature_names(lst))], axis = 1)\n",
    "for k in [1,3,5,7,9,21,31]:\n",
    "    accs = []\n",
    "    sens = []\n",
    "    specs = []\n",
    "    for i in range(0,5):\n",
    "        X_train, X_test, y_train, y_test = train_test_split(\n",
    "            X.drop(columns = ['test_cas', 'conc1_mean','smiles','pubchem2d']), db['conc1_mean'], test_size = 0.33)\n",
    "        \n",
    "        minmax = MinMaxScaler()\n",
    "        minmax.fit(X_train[numerical])\n",
    "        \n",
    "        new_train = X_train.copy()\n",
    "        new_train.loc[:, numerical] = minmax.transform(X_train[numerical])\n",
    "\n",
    "        new_test = X_test.copy()\n",
    "        new_test.loc[:, numerical] = minmax.transform(X_test[numerical])\n",
    "        \n",
    "        \n",
    "        knn = KNeighborsClassifier(n_neighbors = k)\n",
    "        knn.fit(new_train, y_train)\n",
    "        y_pred = knn.predict(new_test)\n",
    "        accs.append(accuracy_score(y_test, y_pred))\n",
    "        sens.append(recall_score(y_test, y_pred))\n",
    "\n",
    "        tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "\n",
    "        specs.append(tn/(tn+fp))\n",
    "    print('K=',k)\n",
    "    print('Accuracy:', np.mean(accs), 'se:', sem(accs))\n",
    "    print('Sensitivity:', np.mean(sens), 'se:', sem(sens))\n",
    "    print('Specificity:', np.mean(specs), 'se:', sem(specs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utilizzo solo chemicals e pubchem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical = ['atom_number', 'bonds_number','Mol', 'MorganDensity', 'LogP',\n",
    "            'alone_atom_number', 'doubleBond', 'tripleBond', 'ring_number', 'oh_count', 'MeltingPoint', 'WaterSolubility']\n",
    "\n",
    "categorical = ['obs_duration_mean', 'conc1_type', 'exposure_type', 'control_type', 'media_type',\n",
    "               'application_freq_unit', 'species', 'class', 'tax_order', 'family', 'genus']\n",
    "\n",
    "db_chem = db.drop(columns = ['test_cas', 'smiles', 'conc1_mean'] + categorical).copy()\n",
    "pub = pd.DataFrame(pd.DataFrame(db_chem['pubchem2d'].values).apply(lambda x: x.str.replace('', ' ').str.strip().str.split(' '),\n",
    "                                                        axis = 1)[0].to_list(),\n",
    "                   columns = ['pub'+ str(i) for i in range(1,882)])\n",
    "\n",
    "db_chem = pd.concat([db_chem.drop(columns = 'pubchem2d'), pub], axis = 1)\n",
    "\n",
    "y = db['conc1_mean']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K=1,3,5,7,9,21,31 (NO MinMax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K= 1\n",
      "Accuracy: 0.8346831250940839 se: 0.004222858779665728\n",
      "Sensitivity: 0.8101578006683028 se: 0.017482921665178945\n",
      "Specificity: 0.8500590283624406 se: 0.006741577575219079\n",
      "K= 3\n",
      "Accuracy: 0.8492548547343068 se: 0.0030011137847981637\n",
      "Sensitivity: 0.793059214197143 se: 0.00920258401894953\n",
      "Specificity: 0.8843256133007499 se: 0.0063573395746343775\n",
      "K= 5\n",
      "Accuracy: 0.852566611470721 se: 0.003030418562850423\n",
      "Sensitivity: 0.803792542703589 se: 0.013544666211379631\n",
      "Specificity: 0.8832261675647629 se: 0.009529731339229458\n",
      "K= 7\n",
      "Accuracy: 0.8559686888454012 se: 0.00475040383521085\n",
      "Sensitivity: 0.8025167759450534 se: 0.002668967374408196\n",
      "Specificity: 0.8887447351503281 se: 0.008002225416072118\n",
      "K= 9\n",
      "Accuracy: 0.8513924431732651 se: 0.001949638385596416\n",
      "Sensitivity: 0.8021894322195907 se: 0.00574673615694617\n",
      "Specificity: 0.8819995393162596 se: 0.0041988420065658975\n",
      "K= 21\n",
      "Accuracy: 0.8389884088514223 se: 0.002191090074491929\n",
      "Sensitivity: 0.7589654944887341 se: 0.0049965138392162566\n",
      "Specificity: 0.8891359491303789 se: 0.004720461919292942\n",
      "K= 31\n",
      "Accuracy: 0.8317025440313112 se: 0.001061240808792079\n",
      "Sensitivity: 0.7254523389510965 se: 0.011117129138419796\n",
      "Specificity: 0.8972684558251782 se: 0.007023792349237913\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, recall_score, confusion_matrix\n",
    "from scipy.stats import sem\n",
    "from sklearn.preprocessing import OneHotEncoder, MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "for k in [1,3,5,7,9,21,31]:\n",
    "    accs = []\n",
    "    sens = []\n",
    "    specs = []\n",
    "    for i in range(0,5):\n",
    "        X_train, X_test, y_train, y_test = train_test_split(db_chem, y, test_size = 0.33)\n",
    "\n",
    "        knn = KNeighborsClassifier(n_neighbors = k)\n",
    "        knn.fit(X_train, y_train)\n",
    "        y_pred = knn.predict(X_test)\n",
    "        accs.append(accuracy_score(y_test, y_pred))\n",
    "        sens.append(recall_score(y_test, y_pred))\n",
    "\n",
    "        tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "\n",
    "        specs.append(tn/(tn+fp))\n",
    "    print('K=',k)\n",
    "    print('Accuracy:', np.mean(accs), 'se:', sem(accs))\n",
    "    print('Sensitivity:', np.mean(sens), 'se:', sem(sens))\n",
    "    print('Specificity:', np.mean(specs), 'se:', sem(specs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Con MinMax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K= 1\n",
      "Accuracy: 0.8319735059461086 se: 0.004267431120909877\n",
      "Sensitivity: 0.8058699052847939 se: 0.012743254463908645\n",
      "Specificity: 0.8484575576447219 se: 0.011375502565391655\n",
      "K= 3\n",
      "Accuracy: 0.8545536655125696 se: 0.003998495098077015\n",
      "Sensitivity: 0.7906352041707564 se: 0.012547149691725963\n",
      "Specificity: 0.894546662474087 se: 0.0051685367866523\n",
      "K= 5\n",
      "Accuracy: 0.8556375131717597 se: 0.005499761374020667\n",
      "Sensitivity: 0.8081293787079609 se: 0.012735825707696125\n",
      "Specificity: 0.8850707609313403 se: 0.002130012717255321\n",
      "K= 7\n",
      "Accuracy: 0.8578654222489839 se: 0.0007885473944729011\n",
      "Sensitivity: 0.8049642288771028 se: 0.004497814317707801\n",
      "Specificity: 0.8911518394209361 se: 0.0018775599415625235\n",
      "K= 9\n",
      "Accuracy: 0.8563600782778865 se: 0.0017185992023498514\n",
      "Sensitivity: 0.8017340570195385 se: 0.007783766843959338\n",
      "Specificity: 0.8905794119341308 se: 0.006685004349538903\n",
      "K= 21\n",
      "Accuracy: 0.8555170856540719 se: 0.001119838320842826\n",
      "Sensitivity: 0.7768338397214845 se: 0.008570442372695872\n",
      "Specificity: 0.9041138460206696 se: 0.00463691948780822\n",
      "K= 31\n",
      "Accuracy: 0.8455517085654073 se: 0.0012404253544755458\n",
      "Sensitivity: 0.7555059495588134 se: 0.010267026992568335\n",
      "Specificity: 0.9006192403538777 se: 0.006056122786569335\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, recall_score, confusion_matrix\n",
    "from scipy.stats import sem\n",
    "from sklearn.preprocessing import OneHotEncoder, MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "numerical = ['atom_number', 'bonds_number','Mol', 'MorganDensity', 'LogP',\n",
    "            'alone_atom_number', 'doubleBond', 'tripleBond', 'ring_number', 'oh_count', 'MeltingPoint', 'WaterSolubility']\n",
    "\n",
    "for k in [1,3,5,7,9,21,31]:\n",
    "    accs = []\n",
    "    sens = []\n",
    "    specs = []\n",
    "    for i in range(0,5):\n",
    "        X_train, X_test, y_train, y_test = train_test_split(db_chem, y, test_size = 0.33)\n",
    "    \n",
    "        minmax = MinMaxScaler()\n",
    "        minmax.fit(X_train[numerical])\n",
    "        \n",
    "        new_train = X_train.copy()\n",
    "        new_train.loc[:, numerical] = minmax.transform(X_train[numerical])\n",
    "\n",
    "        new_test = X_test.copy()\n",
    "        new_test.loc[:, numerical] = minmax.transform(X_test[numerical])\n",
    "        \n",
    "        knn = KNeighborsClassifier(n_neighbors = k)\n",
    "        knn.fit(new_train, y_train)\n",
    "        y_pred = knn.predict(new_test)\n",
    "        accs.append(accuracy_score(y_test, y_pred))\n",
    "        sens.append(recall_score(y_test, y_pred))\n",
    "\n",
    "        tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "\n",
    "        specs.append(tn/(tn+fp))\n",
    "    print('K=',k)\n",
    "    print('Accuracy:', np.mean(accs), 'se:', sem(accs))\n",
    "    print('Sensitivity:', np.mean(sens), 'se:', sem(sens))\n",
    "    print('Specificity:', np.mean(specs), 'se:', sem(specs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TUTTO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# carico i dati\n",
    "db = pd.read_csv('lc_db_processed.csv').drop(columns = ['Unnamed: 0', 'fish'])\n",
    "\n",
    "# tolgo dal dataset info inutili\n",
    "db.drop(columns = ['test_cas', 'smiles'], inplace = True)\n",
    "\n",
    "# unisco al dataset i pub\n",
    "db = pd.concat([db,\n",
    "                pd.DataFrame(pd.DataFrame(db['pubchem2d'].values).\\\n",
    "                             apply(lambda x: x.str.replace('', ' ').str.strip().str.split(' '), \n",
    "                                                                        axis = 1)[0].to_list(),\n",
    "                   columns = ['pub'+ str(i) for i in range(1,882)])],\n",
    "               axis = 1)\n",
    "\n",
    "# one hot encoding di categoriche\n",
    "categorical = ['obs_duration_mean', 'conc1_type', 'exposure_type', 'control_type', 'media_type',\n",
    "               'application_freq_unit', 'species', 'class', 'tax_order', 'family', 'genus']\n",
    "\n",
    "ohe = OneHotEncoder(sparse = False)\n",
    "ohe.fit(db[categorical])\n",
    "\n",
    "finaldb = pd.concat([db.drop(columns =categorical), \n",
    "                     pd.DataFrame(ohe.transform(db[categorical]), columns = ohe.get_feature_names(categorical))],\n",
    "                    axis = 1)\n",
    "\n",
    "#trasformo in variabile dicotomica la target \n",
    "finaldb['conc1_mean'] = np.where(finaldb['conc1_mean'].values > 1, 0, 1)\n",
    "\n",
    "# mi preparo\n",
    "X = finaldb.drop(columns = ['conc1_mean', 'pubchem2d'])\n",
    "y = finaldb['conc1_mean'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NO MinMax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K= 1\n",
      "Accuracy: 0.9140995701851014 se: 0.0014541868036512522\n",
      "Sensitivity: 0.885716811157683 se: 0.0034567513587959926\n",
      "Specificity: 0.9317999922521742 se: 0.002626326772853722\n",
      "K= 3\n",
      "Accuracy: 0.9101748448747736 se: 0.0010623856935982287\n",
      "Sensitivity: 0.8737091713429848 se: 0.0014833638290170604\n",
      "Specificity: 0.9328649159017905 se: 0.0014501000843438485\n",
      "K= 5\n",
      "Accuracy: 0.8999404368499165 se: 0.0013072162565040605\n",
      "Sensitivity: 0.8569708650675677 se: 0.0014074309912032632\n",
      "Specificity: 0.9266728330681708 se: 0.0016865673050240216\n",
      "K= 7\n",
      "Accuracy: 0.8917430367209412 se: 0.0016207459039843817\n",
      "Sensitivity: 0.8420033562459086 se: 0.003645510925729025\n",
      "Specificity: 0.9225558517643397 se: 0.001001467103075792\n",
      "K= 9\n",
      "Accuracy: 0.8868741873474588 se: 0.0017912092456544542\n",
      "Sensitivity: 0.832530290045953 se: 0.0036018896586509338\n",
      "Specificity: 0.9205402471073649 se: 0.0014508442824272601\n",
      "K= 21\n",
      "Accuracy: 0.8635729991082807 se: 0.0008882576391409451\n",
      "Sensitivity: 0.7913283220035331 se: 0.002252780394520117\n",
      "Specificity: 0.9084810631618364 se: 0.0020754077370473034\n",
      "K= 31\n",
      "Accuracy: 0.8486684130789619 se: 0.0012755650544815681\n",
      "Sensitivity: 0.7646433670228103 se: 0.0022879993588150356\n",
      "Specificity: 0.9009109906158924 se: 0.0015493879456634388\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, recall_score, confusion_matrix\n",
    "from scipy.stats import sem\n",
    "from sklearn.preprocessing import OneHotEncoder, MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "\n",
    "for k in [1,3,5,7,9,21,31]:\n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state = 5645)\n",
    "    accs = []\n",
    "    sens = []\n",
    "    specs = []\n",
    "    for train_index, test_index in kf.split(X):\n",
    "        X_train = X.iloc[train_index]\n",
    "        X_test = X.iloc[test_index]\n",
    "        y_train = y[train_index]\n",
    "        y_test = y[test_index]\n",
    "\n",
    "        knn = KNeighborsClassifier(n_neighbors = k, n_jobs = -1)\n",
    "        knn.fit(X_train, y_train)\n",
    "        y_pred = knn.predict(X_test)\n",
    "\n",
    "        tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "\n",
    "        accs.append(accuracy_score(y_test, y_pred))\n",
    "        sens.append(recall_score(y_test, y_pred))\n",
    "        specs.append(tn/(tn+fp))\n",
    "    \n",
    "    print('K=', k)\n",
    "    print('Accuracy:', np.mean(accs), 'se:', sem(accs))\n",
    "    print('Sensitivity:', np.mean(sens), 'se:', sem(sens))\n",
    "    print('Specificity:', np.mean(specs), 'se:', sem(specs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Con MinMax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K= 1\n",
      "Accuracy: 0.9103236663550278 se: 0.0010966817214079002\n",
      "Sensitivity: 0.8761944273294576 se: 0.0026436275744497364\n",
      "Specificity: 0.9315736817205504 se: 0.0018044452167607166\n",
      "K= 3\n",
      "Accuracy: 0.9095783000558482 se: 0.001991825984733374\n",
      "Sensitivity: 0.8740572890797518 se: 0.0044766233050480735\n",
      "Specificity: 0.9316329032593336 se: 0.0008666105102434687\n",
      "K= 5\n",
      "Accuracy: 0.9014306510785485 se: 0.0013535523593969576\n",
      "Sensitivity: 0.8595549448229709 se: 0.0026309507041491023\n",
      "Specificity: 0.9274611313985186 se: 0.000915749598720235\n",
      "K= 7\n",
      "Accuracy: 0.8935313135427178 se: 0.0010221333891341135\n",
      "Sensitivity: 0.8436841696866674 se: 0.0015457904087716437\n",
      "Specificity: 0.9245076112762266 se: 0.0016854417380099337\n",
      "K= 9\n",
      "Accuracy: 0.8905006032219147 se: 0.0019889892983018824\n",
      "Sensitivity: 0.833463048958359 se: 0.002504261588197031\n",
      "Specificity: 0.9259625567233698 se: 0.0021706412798334863\n",
      "K= 21\n",
      "Accuracy: 0.8700811680597853 se: 0.002194247114340109\n",
      "Sensitivity: 0.7933674060204515 se: 0.005113798172349682\n",
      "Specificity: 0.9177803892057984 se: 0.002781631636775592\n",
      "K= 31\n",
      "Accuracy: 0.8611880417040787 se: 0.0020922950906462215\n",
      "Sensitivity: 0.7784086067307785 se: 0.004316253930288424\n",
      "Specificity: 0.912678300719941 se: 0.0021945688799005687\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, recall_score, confusion_matrix\n",
    "from scipy.stats import sem\n",
    "from sklearn.preprocessing import OneHotEncoder, MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "\n",
    "numerical = ['atom_number', 'bonds_number','Mol', 'MorganDensity', 'LogP',\n",
    "            'alone_atom_number', 'doubleBond', 'tripleBond', 'ring_number', 'oh_count', 'MeltingPoint', 'WaterSolubility']\n",
    "\n",
    "for k in [1,3,5,7,9,21,31]:\n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state = 5645)\n",
    "    accs = []\n",
    "    sens = []\n",
    "    specs = []\n",
    "    for train_index, test_index in kf.split(X):\n",
    "        X_train = X.iloc[train_index]\n",
    "        X_test = X.iloc[test_index]\n",
    "        y_train = y[train_index]\n",
    "        y_test = y[test_index]\n",
    "        \n",
    "        minmax = MinMaxScaler()\n",
    "        minmax.fit(X_train[numerical])\n",
    "        \n",
    "        new_train = X_train.copy()\n",
    "        new_train.loc[:, numerical] = minmax.transform(X_train[numerical])\n",
    "\n",
    "        new_test = X_test.copy()\n",
    "        new_test.loc[:, numerical] = minmax.transform(X_test[numerical])\n",
    "        \n",
    "        knn = KNeighborsClassifier(n_neighbors = k, n_jobs = -1)\n",
    "        knn.fit(new_train, y_train)\n",
    "        y_pred = knn.predict(new_test)\n",
    "\n",
    "        tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "\n",
    "        accs.append(accuracy_score(y_test, y_pred))\n",
    "        sens.append(recall_score(y_test, y_pred))\n",
    "        specs.append(tn/(tn+fp))\n",
    "    \n",
    "    print('K=', k)\n",
    "    print('Accuracy:', np.mean(accs), 'se:', sem(accs))\n",
    "    print('Sensitivity:', np.mean(sens), 'se:', sem(sens))\n",
    "    print('Specificity:', np.mean(specs), 'se:', sem(specs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "k1 = {\n",
    "'Accuracy': 0.9103236663550278,\n",
    "'Sensitivity': 0.8761944273294576,\n",
    "'Specificity': 0.9315736817205504\n",
    "}\n",
    "k3 = {\n",
    "'Accuracy': 0.9095783000558482,\n",
    "'Sensitivity': 0.8740572890797518,\n",
    "'Specificity': 0.9316329032593336\n",
    "}\n",
    "k5 = {\n",
    "'Accuracy': 0.9014306510785485,\n",
    "'Sensitivity': 0.8595549448229709,\n",
    "'Specificity': 0.9274611313985186 \n",
    "}\n",
    "\n",
    "k7 = {\n",
    "'Accuracy': 0.8935313135427178,\n",
    "'Sensitivity': 0.8436841696866674,\n",
    "'Specificity': 0.9245076112762266 \n",
    "}\n",
    "k9 = {\n",
    "'Accuracy': 0.8905006032219147,\n",
    "'Sensitivity': 0.833463048958359,\n",
    "'Specificity': 0.925962556723369863\n",
    "}\n",
    "k21 = {\n",
    "'Accuracy': 0.8700811680597853,\n",
    "'Sensitivity': 0.7933674060204515,\n",
    "'Specificity': 0.9177803892057984 \n",
    "}\n",
    "k31 = {\n",
    "'Accuracy': 0.8611880417040787 ,\n",
    "'Sensitivity': 0.7784086067307785 ,\n",
    "'Specificity': 0.912678300719941\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "accs = list()\n",
    "accs.append(k1['Accuracy'])\n",
    "accs.append(k3['Accuracy'])\n",
    "accs.append(k5['Accuracy'])\n",
    "accs.append(k7['Accuracy'])\n",
    "accs.append(k9['Accuracy'])\n",
    "accs.append(k21['Accuracy'])\n",
    "accs.append(k31['Accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'KNN Table 3')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot([1,3,5,7,9,21,31], accs, '-o')\n",
    "plt.xlabel('K', fontsize = 15)\n",
    "plt.ylabel('Accuracy', fontsize = 15)\n",
    "plt.title('KNN Table 3')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
